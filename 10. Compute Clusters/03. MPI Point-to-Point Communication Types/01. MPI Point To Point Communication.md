## MPI Point-to-Point Communication

### Introdução
O Message Passing Interface (MPI) é uma interface de programação dominante para comunicação entre processos em um cluster de computação [^408]. Dentro do MPI, existem dois tipos principais de comunicação: ponto a ponto e coletiva. Este capítulo se concentrará nos tipos de comunicação ponto a ponto, explorando os conceitos fundamentais e as funções API associadas. A comunicação ponto a ponto envolve um processo de origem e um processo de destino [^414], similar a um sistema telefônico onde um chamador disca um número e um receptor atende a chamada [^408].

### Conceitos Fundamentais

A comunicação ponto a ponto é um dos dois principais paradigmas de comunicação suportados pelo MPI [^414]. Ela envolve a transferência de dados diretamente de um processo de origem para um processo de destino. As duas funções principais utilizadas nesta forma de comunicação são `MPI_Send()` e `MPI_Recv()` [^414].

**Função MPI_Send()**

A função `MPI_Send()` é chamada pelo processo de origem para enviar dados para o processo de destino [^414]. A Figura 19.7 [^414] mostra a sintaxe para usar a função `MPI_Send()`. Seus parâmetros são:

*   `buf`: Um ponteiro para o local inicial da área de memória onde os dados a serem enviados podem ser encontrados [^414].
*   `count`: Um inteiro que fornece o número de elementos de dados a serem enviados [^414].
*   `datatype`: Um tipo MPI embutido que especifica o tipo de cada elemento de dados que está sendo enviado. Este parâmetro é definido em `mpi.h` e inclui `MPI_DOUBLE` (ponto flutuante de dupla precisão), `MPI_FLOAT` (ponto flutuante de precisão simples), `MPI_INT` (inteiro) e `MPI_CHAR` (caractere). Os tamanhos exatos desses tipos dependem do tamanho dos tipos C correspondentes no processador host [^414].
*   `dest`: Um inteiro que fornece o rank MPI do processo de destino [^414].
*   `tag`: Um inteiro que fornece uma tag que pode ser usada para classificar as mensagens enviadas pelo mesmo processo [^414].
*   `comm`: Um comunicador que seleciona os processos a serem considerados na comunicação [^414].

**Função MPI_Recv()**

A função `MPI_Recv()` é chamada pelo processo de destino para receber os dados enviados pelo processo de origem [^414]. A Figura 19.8 [^415] mostra a sintaxe para usar a função `MPI_Recv()`. Seus parâmetros são:

*   `buf`: Um ponteiro para a área na memória onde os dados recebidos devem ser depositados [^414].
*   `count`: Um inteiro que fornece o número máximo de elementos que a função `MPI_Recv()` tem permissão para receber [^414].
*   `datatype`: Um tipo MPI que especifica o tipo (tamanho) de cada elemento a ser recebido [^415].
*   `source`: Um inteiro que fornece o ID do processo da fonte da mensagem [^415].
*   `tag`: Um inteiro que especifica o valor da tag particular esperado pelo processo de destino. Se o processo de destino não quiser ser limitado a um valor de tag particular, ele pode usar `MPI_ANY_TAG`, o que significa que o receptor está disposto a aceitar mensagens de qualquer valor de tag da fonte [^415].
*   `comm`: Um comunicador que seleciona os processos a serem considerados na comunicação [^415].
*   `status`: Um objeto de status [^415].

**Exemplo de uso**

Para ilustrar o uso da comunicação ponto a ponto, o contexto apresenta um exemplo de um servidor de dados que inicializa dados com números aleatórios e distribui os dados para os processos de computação [^415]. O servidor de dados envia partições do grid 3D para cada processo de computação usando a função `MPI_Send()` [^418]. Os processos de computação, por sua vez, recebem esses dados usando a função `MPI_Recv()` [^420].

**Comunicação Blocking e Non-Blocking**

As funções `MPI_Send()` e `MPI_Recv()` podem ser blocking ou non-blocking. Em uma comunicação blocking, a função só retorna quando a operação de comunicação é concluída [^432]. Isso significa que, no caso de `MPI_Send()`, a função retorna somente quando os dados foram copiados para um buffer de envio ou foram enviados para o destino. No caso de `MPI_Recv()`, a função retorna somente quando os dados foram recebidos e armazenados no buffer de recebimento.

A comunicação non-blocking, por outro lado, permite que a função retorne imediatamente, mesmo antes da operação de comunicação ser concluída [^432]. Isso permite que o processo continue executando outras tarefas enquanto a comunicação está em andamento. Para verificar se a operação de comunicação foi concluída, é necessário usar funções adicionais como `MPI_Wait()` ou `MPI_Test()`.\

### Conclusão
A comunicação ponto a ponto é um componente fundamental da programação MPI, permitindo que processos individuais troquem dados diretamente uns com os outros [^414]. As funções `MPI_Send()` e `MPI_Recv()` são as ferramentas principais para implementar este tipo de comunicação [^414]. Compreender os parâmetros dessas funções e os conceitos de comunicação blocking e non-blocking é essencial para desenvolver aplicações MPI eficientes. Além disso, técnicas como o overlapping de computação e comunicação, discutido posteriormente no capítulo [^421], podem ser usadas para otimizar ainda mais o desempenho das aplicações MPI.

### Referências

[^408]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 408.
[^414]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 414.
[^415]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 415.
[^418]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 418.
[^420]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 420.
[^421]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 421.
[^432]: Programming a Heterogeneous Computing Cluster, CHAPTER 19, page 432.
<!-- END -->