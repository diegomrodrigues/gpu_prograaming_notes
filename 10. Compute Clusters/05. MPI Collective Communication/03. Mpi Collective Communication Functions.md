## MPI Collective Communication: Broadcast, Reduction, Gather, and Scatter

### Introdução
Em continuidade à discussão sobre comunicação MPI, este capítulo aprofunda-se nas funções de **comunicação coletiva** [^431]. Como mencionado anteriormente, a comunicação coletiva envolve um grupo de processos MPI, contrastando com a comunicação ponto a ponto, que envolve apenas um processo de origem e um de destino [^414]. Já vimos um exemplo de comunicação coletiva com a função `MPI_Barrier` [^431]. Este capítulo irá introduzir brevemente outras funções de comunicação coletiva comuns, nomeadamente *broadcast*, *reduction*, *gather* e *scatter* [^431].

### Conceitos Fundamentais

1.  **Broadcast:**
    A função **broadcast** é utilizada para enviar dados de um único processo (*root*) para todos os outros processos num comunicador. O *root* envia os dados, e todos os outros processos recebem uma cópia desses dados. Esta função é útil quando todos os processos precisam ter acesso aos mesmos dados, como por exemplo, parâmetros de configuração ou tabelas de pesquisa.

2.  **Reduction:**
    A função **reduction** combina dados de todos os processos num comunicador utilizando uma operação especificada (e.g., soma, produto, máximo, mínimo) e envia o resultado para um único processo (*root*). Por exemplo, se cada processo tiver um valor, uma operação de redução de soma irá somar todos os valores e enviar a soma total para o processo *root*. Esta função é útil para calcular estatísticas globais ou combinar resultados parciais de diferentes processos.

3.  **Gather:**
    A função **gather** coleta dados de todos os processos num comunicador e envia-os para um único processo (*root*). Cada processo contribui com uma parte dos dados, e o processo *root* recebe todos os dados combinados. Esta função é útil quando é necessário reunir resultados parciais de diferentes processos para processamento posterior.

4.  **Scatter:**
    A função **scatter** distribui dados de um único processo (*root*) para todos os outros processos num comunicador. O processo *root* tem um conjunto de dados, e cada processo recebe uma parte desse conjunto. Esta função é útil quando é necessário distribuir diferentes dados para diferentes processos, como por exemplo, distribuir diferentes partes de uma matriz para diferentes processos para processamento paralelo.

É importante notar que estas funções são altamente otimizadas pelas implementações de MPI [^431]. A utilização destas funções, em vez de implementar as mesmas operações manualmente utilizando comunicação ponto a ponto, geralmente resulta em melhor desempenho, bem como maior legibilidade e produtividade do código [^431].

A função `MPI_Barrier()` exemplifica a utilização de comunicação coletiva, onde todos os processos aguardam até que todos os outros atinjam um determinado ponto no código [^431, 426]. Isto é crucial para garantir que todos os processos estejam prontos antes de iniciarem uma nova fase de computação ou comunicação [^426]. No exemplo do *stencil*, `MPI_Barrier()` é utilizado para garantir que todos os processos tenham recebido os seus dados de entrada antes de iniciar a computação [^426].

### Conclusão
As funções de comunicação coletiva, como *broadcast*, *reduction*, *gather* e *scatter*, são ferramentas poderosas no MPI para facilitar a comunicação e sincronização entre grupos de processos. A função `MPI_Barrier()` exemplifica a comunicação coletiva, onde todos os processos precisam de estar sincronizados. Ao utilizar estas funções otimizadas, os programadores podem escrever código mais eficiente, legível e produtivo para aplicações paralelas complexas.

### Referências
[^414]: MPI Point-to-Point Communication Types
[^426]: MPI_Barrier function
[^431]: MPI Collective Communication

<!-- END -->