## MPI Process Addressing: A Logical Number System

### Introdução
O **Message Passing Interface (MPI)** é uma interface de programação dominante para computação em clusters [^408]. Ele oferece um conjunto de funções de API para comunicação entre processos que estão sendo executados em um cluster de computação. No modelo de memória distribuída do MPI, os processos trocam informações enviando mensagens uns aos outros [^408]. Uma característica fundamental do MPI é sua capacidade de permitir que os processos se enderecem usando números lógicos, uma abstração que simplifica a comunicação em ambientes complexos [^408]. Este capítulo explorará este sistema de endereçamento lógico em detalhes.

### Conceitos Fundamentais
No MPI, cada processo é atribuído a um identificador único dentro de um *comunicador*. Este identificador, conhecido como **MPI rank** ou **process ID**, é um número inteiro não negativo que varia de 0 até o número total de processos menos 1 [^411].

**Analogia com um Sistema Telefônico:**
A forma como os processos MPI se endereçam uns aos outros usando ranks é análoga ao uso de números de telefone em um sistema telefônico [^408]. Assim como os usuários de telefone podem discar uns para os outros usando números de telefone sem saber exatamente onde a pessoa chamada está localizada ou como a chamada é roteada, os processos MPI podem se comunicar usando ranks sem se preocupar com os detalhes da rede de interconexão subjacente [^408].

**Funções para Determinar Ranks e Tamanho:**
O MPI fornece duas funções essenciais para determinar os ranks dos processos e o tamanho do comunicador:
*   `MPI_Comm_rank()`: Esta função retorna o rank exclusivo do processo de chamada dentro de um comunicador especificado [^411]. Ela recebe dois parâmetros: o comunicador (`MPI_Comm`) e um ponteiro para uma variável inteira onde o rank será armazenado [^411].
*   `MPI_Comm_size()`: Esta função retorna o número total de processos no comunicador [^411]. Ela também recebe o comunicador (`MPI_Comm`) e um ponteiro para uma variável inteira onde o tamanho será armazenado [^411].

**Exemplo:**
Considere o seguinte trecho de código C:
```c
#include "mpi.h"
int main(int argc, char *argv[]) {
    int rank, size;
    MPI_Init(&argc, &argv);
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);
    printf("Rank = %d, Size = %d\\n", rank, size);
    MPI_Finalize();
    return 0;
}
```
Neste exemplo, `MPI_COMM_WORLD` é um comunicador predefinido que inclui todos os processos MPI em execução na aplicação [^411]. Cada processo irá imprimir seu rank e o número total de processos.

**Comunicadores:**
Um **comunicador** define um grupo de processos que podem se comunicar entre si [^411]. O `MPI_COMM_WORLD` é o comunicador padrão, mas os aplicativos MPI podem criar comunicadores adicionais para permitir a comunicação dentro de subconjuntos de processos [^411]. Isso pode ser útil para organizar a comunicação em aplicações paralelas complexas.

**Comunicação Ponto a Ponto:**
As funções `MPI_Send()` e `MPI_Recv()` são usadas para comunicação ponto a ponto, onde uma mensagem é enviada de um processo de origem para um processo de destino [^414]. O rank do processo de destino é especificado na função `MPI_Send()`, e o rank do processo de origem é especificado (ou pode ser um curinga) na função `MPI_Recv()` [^414].

**Exemplo:**
O código abaixo ilustra a comunicação ponto a ponto usando os ranks dos processos:
```c
#include "mpi.h"
#include <stdio.h>

int main(int argc, char** argv) {
    MPI_Init(&argc, &argv);

    int rank, size;
    MPI_Comm_rank(MPI_COMM_WORLD, &rank);
    MPI_Comm_size(MPI_COMM_WORLD, &size);

    int message;

    if (rank == 0) {
        message = 123;
        MPI_Send(&message, 1, MPI_INT, 1, 0, MPI_COMM_WORLD);
        printf("Process %d sent message %d to process 1\\n", rank, message);
    } else if (rank == 1) {
        MPI_Recv(&message, 1, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE);
        printf("Process %d received message %d from process 0\\n", rank, message);
    }

    MPI_Finalize();
    return 0;
}
```
Neste exemplo, o processo com rank 0 envia uma mensagem para o processo com rank 1.

### Conclusão
O sistema de endereçamento lógico fornecido pelas implementações MPI é uma ferramenta fundamental para simplificar a comunicação entre processos em ambientes de computação paralela [^408]. Ao abstrair os detalhes da rede de interconexão subjacente, o MPI permite que os programadores se concentrem na lógica de suas aplicações paralelas. O uso de ranks de processo e comunicadores fornece uma maneira flexível e poderosa de organizar a comunicação em aplicações MPI, permitindo o desenvolvimento de aplicações paralelas escaláveis e eficientes.

### Referências
[^408]: Programming a Heterogeneous Computing Cluster, Chapter 19, page 408.
[^411]: Programming a Heterogeneous Computing Cluster, Chapter 19, page 411.
[^414]: Programming a Heterogeneous Computing Cluster, Chapter 19, page 414.
<!-- END -->