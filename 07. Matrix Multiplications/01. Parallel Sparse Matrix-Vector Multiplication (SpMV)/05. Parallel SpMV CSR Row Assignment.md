## Capítulo 5: Paralelização de SpMV Usando CSR

### Introdução
Este capítulo explora a paralelização da multiplicação esparsa matriz-vetor (SpMV) utilizando o formato Compressed Sparse Row (CSR) em CUDA. Em particular, focaremos na abordagem onde cada linha da matriz esparsa é atribuída a um thread para o cálculo do produto escalar correspondente. Essa estratégia se aproveita da independência inerente aos cálculos das linhas. Analisaremos as limitações dessa abordagem, como acessos não coalescidos à memória e divergência de fluxo de controle, e como essas limitações afetam a eficiência do SpMV.

### Conceitos Fundamentais

A multiplicação esparsa matriz-vetor (SpMV) é uma operação fundamental em diversas áreas, como análise numérica, aprendizado de máquina e simulações científicas. Dada uma matriz esparsa $A$ de dimensão $m \times n$ e um vetor $x$ de dimensão $n$, o objetivo é calcular o vetor $y$ de dimensão $m$, onde $y = Ax$. Devido à esparsidade de $A$, a representação e o processamento eficientes são cruciais. O formato Compressed Sparse Row (CSR) é uma das representações mais comuns para matrizes esparsas.

![Illustration of sparse matrix-vector multiplication and accumulation (SpMV), where A * X + Y = Y.](./../images/image5.jpg)

**Formato Compressed Sparse Row (CSR)**

No formato CSR, a matriz esparsa $A$ é representada por três arrays:
*   `val`: Um array contendo os valores não nulos da matriz, lidos linha por linha.
*   `col_ind`: Um array contendo os índices das colunas correspondentes aos valores não nulos em `val`.
*   `row_ptr`: Um array contendo os índices para o início de cada linha em `val` e `col_ind`. Especificamente, `row_ptr[i]` armazena o índice no `val` e `col_ind` onde a $i$-ésima linha começa. O último elemento de `row_ptr` (`row_ptr[m]`) contém o número total de elementos não nulos na matriz.

![Representation of a sparse matrix in Compressed Sparse Row (CSR) format using `row_ptr`, `data`, and `col_index` arrays.](./../images/image7.jpg)

![CSR format example showing data, column indices, and row indices for sparse matrix representation.](./../images/image3.jpg)

**Paralelização de SpMV usando CSR**

A abordagem em questão atribui cada linha da matriz esparsa a um thread para o cálculo do produto escalar correspondente [^1]. No contexto CUDA, um kernel é implementado para realizar essa tarefa. Cada thread calcula o produto escalar da sua linha designada com o vetor de entrada $x$.

**Implementação do Kernel CUDA**

Dentro do kernel CUDA, o índice da linha é calculado usando a seguinte fórmula:
$$row\_index = blockIdx.x * blockDim.x + threadIdx.x$$

Onde:
*   `blockIdx.x` é o índice do bloco na grade CUDA.
*   `blockDim.x` é a dimensão do bloco (número de threads por bloco).
*   `threadIdx.x` é o índice do thread dentro do bloco.

**Pseudocódigo do Kernel**

```c++
__global__ void spmv_csr_kernel(const int *row_ptr, const int *col_ind, const double *val, const double *x, double *y, int m) {
    int row = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < m) {
        double sum = 0.0;
        int row_start = row_ptr[row];
        int row_end = row_ptr[row + 1];

        for (int j = row_start; j < row_end; ++j) {
            int col = col_ind[j];
            sum += val[j] * x[col];
        }

        y[row] = sum;
    }
}
```

**Desafios e Limitações**

Apesar da simplicidade conceitual, essa abordagem enfrenta desafios significativos:

1.  **Acessos Não Coalescidos à Memória:** Acesso coalescido à memória é uma prática fundamental para otimizar o desempenho em GPUs. Threads adjacentes em um warp devem acessar posições de memória adjacentes para maximizar a utilização da largura de banda da memória. No entanto, no SpMV, os threads acessam o vetor $x$ em posições determinadas pelos índices das colunas (`col_ind`). Se os elementos não nulos em cada linha não estiverem dispostos de forma que os threads adjacentes acessem dados adjacentes no vetor $x$, os acessos à memória não serão coalescidos, reduzindo o desempenho [^1].

2.  **Divergência de Fluxo de Controle:**  A divergência de fluxo de controle ocorre quando threads dentro de um mesmo warp seguem caminhos de execução diferentes. Isso pode acontecer quando o número de elementos não nulos varia significativamente entre as linhas da matriz. Alguns threads podem precisar executar mais iterações no loop interno do que outros, levando à serialização da execução dentro do warp. Por exemplo, se uma linha tiver poucos elementos não nulos e outra tiver muitos, os threads correspondentes a essa linha com poucos elementos ficarão ociosos enquanto os outros terminam seu loop [^1].

3.  **Dependência dos Dados:**  A eficiência da execução e a utilização da largura de banda da memória são altamente dependentes da estrutura dos dados da matriz esparsa. Matrizes com distribuições irregulares de elementos não nulos ou padrões de acesso à memória não coalescidos terão um desempenho inferior [^1].

### Conclusão

A paralelização de SpMV usando CSR, atribuindo cada linha a um thread, é uma abordagem direta que explora a independência dos cálculos das linhas. No entanto, essa estratégia é suscetível a acessos não coalescidos à memória e divergência de fluxo de controle, o que pode limitar seu desempenho. A eficiência dessa abordagem depende fortemente das características da matriz esparsa. Técnicas mais avançadas, como reordenação de linhas e colunas, ou abordagens baseadas em blocos, podem ser necessárias para mitigar essas limitações e melhorar o desempenho do SpMV em GPUs. Análises adicionais e otimizações específicas do domínio são cruciais para obter o máximo desempenho em aplicações práticas.

### Referências
[^1]: Parallel SpMV using CSR assigns each row's dot product calculation to a thread, exploiting the independence of row calculations. A CUDA kernel uses `blockIdx.x * blockDim.x + threadIdx.x` to calculate the row index. However, this approach suffers from non-coalesced memory accesses (adjacent threads accessing nonadjacent memory locations) and potential control flow divergence (due to varying numbers of nonzero elements per row). Execution and memory bandwidth efficiency are highly data-dependent.
<!-- END -->