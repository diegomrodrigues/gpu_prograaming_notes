## Parallel Scan: Uma Primitiva para Algoritmos Paralelos

### Introdução
O *parallel scan*, também conhecido como *prefix sum*, é um padrão fundamental em algoritmos paralelos devido à sua capacidade de transformar operações aparentemente sequenciais em operações paralelas [^1]. Este capítulo explora o conceito de parallel scan, suas aplicações e considerações de eficiência. O parallel scan é usado como uma primitiva em vários algoritmos paralelos, incluindo *radix sort*, *quick sort*, comparação de strings, avaliação de polinômios, solução de recorrências, operações em árvores e histogramas [^1]. A escolha entre o scan inclusivo e exclusivo depende da necessidade específica da aplicação, com o inclusivo fornecendo os pontos de corte e o exclusivo os pontos de partida [^1].

### Conceitos Fundamentais
Matematicamente, uma operação de **scan inclusivo** recebe um operador binário associativo $\\oplus$ e um array de entrada de *n* elementos $[x_0, x_1, ..., x_{n-1}]$, e retorna o array de saída $[x_0, (x_0 \\oplus x_1), ..., (x_0 \\oplus x_1 \\oplus ... \\oplus x_{n-1})]$ [^2]. Por exemplo, se $\\oplus$ for a adição, então uma operação de scan inclusivo no array de entrada $[3, 1, 7, 0, 4, 1, 6, 3]$ retornaria $[3, 4, 11, 11, 15, 16, 22, 25]$ [^2].

Um **scan exclusivo** é similar a um scan inclusivo, com a exceção de que ele retorna o array de saída $[0, x_0, (x_0 \\oplus x_1), ..., (x_0 \\oplus x_1 \\oplus ... \\oplus x_{n-2})]$ [^3]. Ou seja, o primeiro elemento de saída é 0, enquanto o último elemento de saída reflete apenas a contribuição até $x_{n-2}$ [^3].

**Exemplo Prático:**
Para ilustrar as aplicações das operações de scan inclusivo, considere o problema de cortar uma linguiça para um grupo de pessoas [^2]. Suponha que temos uma linguiça de 40 polegadas para ser servida a oito pessoas. Cada pessoa pediu uma quantidade diferente em termos de polegadas: 3, 1, 7, 0, 4, 1, 6, 3 [^2]. Com uma operação de scan inclusivo, podemos calcular todos os pontos de corte com base na quantidade que cada pessoa pede [^2]. Dado um operador de adição e um array de entrada de pedidos $[3, 1, 7, 0, 4, 1, 6, 3]$, a operação de scan inclusivo retorna $[3, 4, 11, 11, 15, 16, 22, 25]$ [^2]. Os números no array de retorno são os locais de corte [^2].

É fácil converter entre a saída do scan inclusivo e a saída do scan exclusivo [^3]. Basta fazer um shift e preencher um elemento [^3]. Ao converter de inclusivo para exclusivo, pode-se simplesmente deslocar todos os elementos para a direita e preencher o valor 0 para o elemento 0 [^3]. Ao converter de exclusivo para inclusivo, precisamos deslocar todos os elementos para a esquerda e preencher o último elemento com o último elemento anterior mais o último elemento de entrada [^3].

Na prática, o parallel scan é frequentemente usado como uma operação primitiva em algoritmos paralelos que realizam *radix sort*, *quick sort*, comparação de strings, avaliação de polinômios, solução de recorrências, operações em árvores e histogramas [^3].

**Algoritmo Sequencial Work-Efficient:**
Antes de apresentar algoritmos de parallel scan e suas implementações, é útil mostrar um algoritmo de scan inclusivo sequencial work-efficient e sua implementação [^3]. Assume-se que a operação é a adição. O algoritmo assume que os elementos de entrada estão no array *x* e os elementos de saída devem ser escritos no array *y* [^3].

```c++
void sequential_scan(float *x, float *y, int Max_i){
  y[0] = x[0];
  for (int i = 1; i < Max_i; i++){
    y[i] = y[i-1] + x[i];
  }
}
```
O algoritmo é work-efficient [^3]. Com um compilador razoavelmente bom, apenas uma adição, um carregamento de memória e um armazenamento de memória são usados no processamento de cada elemento de entrada *x* [^3]. Isso é praticamente o mínimo que se pode fazer [^3].

**Um Parallel Scan Simples:**
Um parallel scan inclusivo simples pode ser implementado realizando uma operação de redução para todos os elementos de saída [^4]. A ideia principal é criar cada elemento rapidamente calculando uma árvore de redução dos elementos de entrada relevantes para cada elemento de saída [^4]. Existem várias maneiras de projetar a árvore de redução para cada elemento de saída [^4]. A Figura 9.1 [^4] ilustra um exemplo.

O algoritmo é um algoritmo de scan in-place que opera em um array XY que originalmente contém elementos de entrada [^4]. Ele então evolui iterativamente o conteúdo do array em elementos de saída [^5]. Antes do início do algoritmo, assume-se que XY[i] contém o elemento de entrada $x_i$ [^5]. No final da iteração *n*, XY[i] conterá a soma de $2^n$ elementos de entrada em e antes da localização [^5]. Ou seja, no final da iteração 1, XY[i] conterá $x_{i-1} + x_i$, e no final da iteração 2, XY[i] conterá $x_{i-3} + x_{i-2} + x_{i-1} + x_i$, e assim por diante [^5].

A Figura 9.1 [^4] ilustra o algoritmo com um exemplo de entrada de 16 elementos. Cada linha vertical representa um elemento do array XY, com XY[0] na posição mais à esquerda [^5]. A direção vertical mostra o progresso das iterações, começando do topo da figura [^5]. Para o scan inclusivo, por definição, $y_0$ é $x_0$, então XY[0] contém sua resposta final [^5]. Na primeira iteração, cada posição diferente de XY[0] recebe a soma de seu conteúdo atual e o de seu vizinho esquerdo [^5].

**Considerações sobre Work Efficiency:**
A work efficiency do kernel na Figura 9.2 [^8] pode ser analisada. Todos os threads iterarão até log(N) passos, onde N é o SECTION_SIZE [^8]. Em cada iteração, o número de threads que não precisam fazer nenhuma adição é igual ao tamanho do stride [^8]. Portanto, a quantidade de trabalho realizado para o algoritmo pode ser calculada como $\\sum(N - stride)$, para strides 1, 2, 4, ..., N/2 (log2(N) termos) [^8]. A primeira parte de cada termo é independente do stride, então eles somam $N \\times log_2(N)$ [^8]. A segunda parte é uma série geométrica familiar e soma até (N - 1) [^8]. Portanto, o número total de operações de adição é $N \\times log_2(N) - (N - 1)$ [^8].

Lembre-se de que o número de operações de adição para um algoritmo de scan sequencial é N - 1 [^8]. Isso pode ser colocado em perspectiva comparando o número de operações de adição para diferentes valores de N, conforme mostrado na Figura 9.4 [^9]. Observe que, mesmo para seções de tamanho modesto, o kernel na Figura 9.2 [^8] faz muito mais trabalho do que o algoritmo sequencial [^8]. No caso de 1.024 elementos, o kernel faz nove vezes mais trabalho do que o código sequencial [^8]. A proporção continuará a crescer à medida que N se tornar maior [^8].

**Um Parallel Scan Work-Efficient:**
Embora o kernel na Figura 9.2 [^9] seja conceitualmente simples, sua work efficiency é muito baixa para muitas aplicações práticas [^9]. Apenas inspecionando as Figuras 9.1 e 9.3, podemos ver que existem oportunidades potenciais para compartilhar alguns resultados intermediários para otimizar as operações realizadas [^9]. No entanto, para permitir mais compartilhamento entre vários threads, precisamos calcular rapidamente os resultados intermediários a serem compartilhados e, em seguida, distribuí-los rapidamente para diferentes threads [^9].

Como sabemos, a maneira paralela mais rápida de produzir valores de soma para um conjunto de valores é uma árvore de redução [^9]. Uma árvore de redução pode gerar a soma para N valores em $log_2(N)$ passos [^9]. Além disso, a árvore também pode gerar um número de sub-somas que podem estar no cálculo de alguns dos valores de saída do scan [^9].

### Conclusão
O parallel scan é uma ferramenta poderosa para transformar algoritmos sequenciais em paralelos. A escolha entre diferentes implementações de parallel scan depende das necessidades específicas da aplicação e das características da arquitetura paralela disponível. Considerações de work efficiency são cruciais para garantir que a paralelização realmente resulte em melhorias de desempenho.

### Referências
[^1]: Parallel scan is used as a primitive in parallel algorithms such as radix sort, quick sort, string comparison, polynomial evaluation, solving recurrences, operations on trees and histograms, due to its ability to transform sequential operations into parallel ones.
[^2]: Mathematically, an inclusive scan operation takes a binary associative operator, and an input array of n elements [x0, X1, Xn-1], and returns the output array [Xo, (Xo X1), ..., (XoX1 Xn-1)].
[^3]: In practice, parallel scan is often used as a primitive operation in parallel algorithms that perform radix sort, quick sort, string comparison, polynomial evaluation, solving recurrences, tree operations, and histograms.
[^4]: We start with a simple parallel inclusive scan algorithm by doing a reduction operation for all output elements. The main idea is to create each element quickly by calculating a reduction tree of the relevant input elements for each output element.
[^5]: The algorithm is an in-place scan algorithm that operates on an array XY that originally contains input elements. It then iteratively evolves the contents of the array into output elements.
[^8]: We now analyze the work efficiency of the kernel in Figure 9.2. All threads will iterate up to log(N) steps, where N is the SECTION_SIZE.
[^9]: While the kernel in Figure 9.2 is conceptually simple, its work efficiency is too low for many practical applications.

<!-- END -->