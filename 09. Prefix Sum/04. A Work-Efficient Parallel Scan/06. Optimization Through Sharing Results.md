## Otimização Através do Compartilhamento de Resultados: Identificação de Oportunidades para Compartilhar Resultados Intermediários entre Threads para Otimizar as Operações

### Introdução
Este capítulo aprofunda a otimização do **parallel scan** através do compartilhamento de resultados intermediários entre threads, focando na identificação de oportunidades para otimizar as operações. Como vimos anteriormente, o **parallel scan** é uma primitiva fundamental para converter operações sequenciais em paralelas [^1]. No entanto, a implementação direta do **parallel scan** pode ser ineficiente em termos de trabalho [^8], o que motiva a busca por abordagens mais otimizadas. Expandindo o conceito apresentado em [^9], este capítulo explora técnicas para reduzir a redundância computacional ao compartilhar resultados intermediários, levando a um **parallel scan** mais eficiente.

### Conceitos Fundamentais
A ineficiência de trabalho em um **parallel scan** simples surge da repetição de cálculos por diferentes threads. Para mitigar essa ineficiência, podemos explorar oportunidades para compartilhar resultados intermediários [^9]. A ideia central é que, se várias threads precisam do mesmo resultado parcial para seus cálculos finais, esse resultado parcial deve ser calculado apenas uma vez e compartilhado entre as threads.

A seção 9.4 [^9] introduz um **work-efficient parallel scan**, que tenta minimizar o número de operações necessárias. Este algoritmo utiliza uma árvore de redução para calcular a soma de *N* valores em log₂(N) passos. Além disso, a árvore gera vários sub-somatórios que podem ser usados no cálculo de alguns dos valores de saída do scan. Essa abordagem é ilustrada na Figura 9.5 [^9].

O primeiro passo do algoritmo envolve uma fase de redução, onde os elementos *XY[i]* são atualizados de acordo com a Figura 9.5 [^9]. Esta fase calcula somas parciais que são então utilizadas na segunda fase do algoritmo. Após a fase de redução, uma árvore reversa é utilizada para distribuir as somas parciais para as posições que podem utilizar esses valores o mais rápido possível. A Figura 9.6 [^10] mostra as somas parciais disponíveis em cada elemento *XY* após a fase de redução.

Para implementar a fase de redução, o seguinte loop pode ser usado [^11]:
```c++
for (unsiged int stride = 1; stride < threadDim.x; stride *= 2)
{
    _synchthreads();
    if ((threadIdx.x + 1)%(2*stride) == 0) {
        XY[threadIdx.x] += XY[threadIdx.x - stride];
    }
}
```
Este loop é similar à redução na Figura 6.2 (não disponível no contexto). A diferença é que queremos que o thread que tem um índice de thread que está na forma de 2ⁿ-1, ao invés de 2ⁿ, execute a adição em cada iteração [^11].

Uma abordagem melhor para evitar problemas de divergência de controle é usar um número decrescente de threads contíguas para executar as adições conforme o loop avança [^12]:
```c++
for (unsigned int stride = 1; stride < blockDim.x; stride *= 2)
{
    _synchthreads();
    int index = (threadIdx.x+1)* 2* stride -1;
    if (index < blockDim.x){
        XY[index] += XY[index - stride];
    }
}
```

A árvore de distribuição é um pouco mais complexa de implementar. Observamos que o valor do *stride* diminui de SECTION_SIZE/2 para 1. Em cada iteração, precisamos "empurrar" o valor do elemento XY de uma posição que é um múltiplo do valor do *stride* menos 1 para uma posição que está a um *stride* de distância [^12].

A Figura 9.7 [^13] mostra o kernel final para um **parallel scan** eficiente em termos de trabalho.

É importante notar que nunca precisamos ter mais do que SECTION_SIZE/2 threads para a fase de redução ou a fase de distribuição. Assim, podemos simplesmente lançar um kernel com SECTION_SIZE/2 threads em um bloco [^13].

### Conclusão
Ao identificar e explorar oportunidades para compartilhar resultados intermediários, é possível otimizar significativamente o desempenho do **parallel scan**. As técnicas apresentadas neste capítulo, como a utilização de árvores de redução e distribuição, permitem reduzir a redundância computacional e alcançar uma maior eficiência de trabalho. A implementação de tais otimizações é crucial para aplicações que exigem alto desempenho e escalabilidade, como aquelas encontradas em computação paralela massiva.

### Referências
[^1]: Página 197: "Parallel scan is frequently used to convert seemingly sequential operations... into parallel operations."
[^8]: Página 204: "We now analyze the work efficiency of the kernel in Figure 9.2."
[^9]: Página 205: "While the kernel in Figure 9.2 is conceptually simple, its work efficiency is too low for many practical applications."
[^10]: Página 206: "FIGURE 9.6 Partial sums available in each XY element after the reduction tree phase."
[^11]: Página 207: "We could implement the reduction tree phase of the parallel scan using the following loop:"
[^12]: Página 208: "A better way to do this is to use a decreasing number of contiguous threads to perform the additions as the loop advances:"
[^13]: Página 209: "Readers should notice that we never need to have more than SECTION_SIZE/2 threads..."
<!-- END -->