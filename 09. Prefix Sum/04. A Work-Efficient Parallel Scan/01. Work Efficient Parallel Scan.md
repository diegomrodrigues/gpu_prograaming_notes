## Trabalho Eficiente de Scan Paralelo Utilizando Árvore de Redução

### Introdução
O padrão de **prefix sum**, também conhecido como *scan*, é uma operação fundamental em computação paralela, frequentemente utilizada para converter operações aparentemente sequenciais em operações paralelas [^1]. No Capítulo 9, foi introduzido um algoritmo de scan paralelo simples, mas com baixa eficiência em termos de trabalho [^9]. Este capítulo foca em detalhar um algoritmo de **scan paralelo work-efficient**, explorando o uso de uma **árvore de redução** para otimizar o cálculo dos prefix sums [^9].

### Conceitos Fundamentais

Um dos métodos mais rápidos para computar a soma de um conjunto de valores em paralelo é através de uma **árvore de redução** [^9]. Uma árvore de redução pode gerar a soma de *N* valores em log₂(N) passos [^9]. Além disso, ela pode gerar um número de sub-somas que podem ser utilizadas no cálculo de alguns dos valores de saída do scan [^9].

O algoritmo de scan paralelo work-efficient aproveita essa estrutura para minimizar o número de operações e maximizar o compartilhamento de resultados intermediários entre as threads [^9].

A ideia básica é dividir o processo em duas fases principais:

1.  **Fase de Redução (Up-Sweep):** Nesta fase, uma árvore de redução é construída para calcular as somas parciais dos elementos de entrada. Cada nível da árvore combina pares de elementos adjacentes, até que a raiz da árvore contenha a soma total de todos os elementos.
2.  **Fase de Distribuição (Down-Sweep):** Nesta fase, as somas parciais calculadas na fase de redução são utilizadas para gerar os valores de saída do scan. A soma total é distribuída para os nós da árvore, e cada nó utiliza a soma recebida para calcular seu próprio valor de scan.

A figura 9.5 [^10] ilustra esse processo, mostrando como a árvore de redução é utilizada para calcular a soma total e como as sub-somas são distribuídas para gerar os valores de saída do scan.

A figura 9.6 [^10] mostra os partial sums disponíveis em cada elemento XY após a fase de redução da árvore.

**Detalhes do Algoritmo:**

Para uma seção de scan de *N* elementos, a fase de redução requer (N/2) + (N/4) + ... + 2 + 1 = N - 1 operações [^10].

A segunda parte do algoritmo utiliza uma árvore reversa para distribuir as somas parciais para as posições que podem utilizar esses valores o mais rápido possível [^10]. A figura 9.5 [^10] ilustra isso na metade inferior.

No final da fase de redução, temos diversas somas parciais utilizáveis [^10]. Por exemplo, a primeira linha da figura 9.6 [^10] mostra todas as somas parciais em XY logo após a árvore de redução superior. Uma observação importante é que XY[0], XY[7] e XY[15] contêm suas respostas finais [^10]. Portanto, todos os elementos XY restantes podem obter as somas parciais de que precisam a não mais de quatro posições de distância [^10]. Por exemplo, XY[14] pode obter todas as somas parciais de que precisa de quatro posições [^10].

A figura 9.5 [^10] mostra como os elementos XY[7], XY[11] e XY[13] são usados para organizar a segunda metade das operações de adição, mostrando todas as operações que precisam de somas parciais de quatro posições de distância, depois duas posições de distância e, em seguida, uma posição de distância [^11].

Um bom caminho é adicionar XY[7] a XY[11], o que traz XY[11] para a resposta final [^11]. Mais importante ainda, XY[7] também se torna uma boa soma parcial para XY[12], XY[13] e XY[14] [^11]. Nenhuma outra soma parcial tem tantos usos [^11]. Portanto, há apenas uma adição, XY[11] = XY[7] + XY[11], que precisa ocorrer no nível de quatro posições na figura 9.5 [^11]. A soma parcial atualizada é mostrada na segunda linha da figura 9.6 [^11].

Agora, identificamos todas as adições para obter somas parciais que estão a duas posições de distância [^11]. Vemos que XY[2] só precisa da soma parcial que está ao lado dele em XY[1] [^11]. O mesmo acontece com XY[4] — ele precisa da soma parcial ao lado dele para ser completo [^11]. O primeiro elemento XY que pode precisar de uma soma parcial a duas posições de distância é XY[5] [^11]. Depois que calculamos XY[5] = XY[3] + XY[5], XY[5] contém a resposta final [^11]. A mesma análise mostra que XY[6] e XY[8] podem se tornar completos com as somas parciais ao lado deles em XY[5] e XY[7] [^11].

A próxima adição de duas posições é XY[9] = XY[7] + XY[9], que torna XY[9] completo [^11]. XY[10] pode esperar a próxima rodada para pegar XY[9] [^11]. XY[12] só precisa de XY[11], que contém sua resposta final após a adição de quatro posições [^11]. A adição final de duas posições é XY[13] = XY[11] + XY[13] [^11]. A terceira linha mostra todas as somas parciais atualizadas em XY[5], XY[9] e XY[13] [^11]. Fica claro que agora todas as posições estão completas ou podem ser completadas quando adicionadas por seu vizinho à esquerda [^11]. Isso leva à linha final de adições na figura 9.5 [^11], que completa o conteúdo para todas as posições incompletas XY[2], XY[4], XY[6], XY[8], XY[10] e XY[12] [^11].

**Implementação:**

O código abaixo ilustra a fase de redução do scan paralelo utilizando uma árvore de redução [^11]:

```c++
for (unsigned int stride = 1; stride < threadDim.x; stride *= 2)
{
    _synchthreads();
    if ((threadIdx.x + 1) % (2 * stride) == 0) {
        XY[threadIdx.x] += XY[threadIdx.x - stride];
    }
}
```

Note que este loop é muito similar à redução na Figura 6.2 [^11]. A única diferença é que queremos que a thread que tem um índice de thread que está na forma de 2ⁿ - 1, em vez de 2ⁿ, execute a adição em cada iteração [^11]. É por isso que adicionamos 1 ao threadIdx.x quando selecionamos as threads para executar a adição em cada iteração [^11]. No entanto, este estilo de redução é conhecido por ter problemas de divergência de controle [^12].

Uma maneira melhor de fazer isso é usar um número decrescente de threads contíguas para executar as adições à medida que o loop avança [^12]:

```c++
for (unsigned int stride = 1; stride < blockDim.x; stride *= 2)
{
    _synchthreads();
    int index = (threadIdx.x+1)* 2* stride -1;
    if (index < blockDim.x){
        XY[index] += XY[index - stride];
    }
}
```

No exemplo da Figura 9.5 [^12], existem 16 threads no bloco. Na primeira iteração, o stride é igual a 1 [^12]. As primeiras 8 threads consecutivas no bloco satisfarão a condição if [^12]. Os valores de índice calculados para essas threads serão 1, 3, 5, 7, 9, 11, 13 e 15 [^12]. Essas threads executarão a primeira linha de adições na Figura 9.5 [^12]. Na segunda iteração, o stride é igual a 2 [^12]. Apenas as primeiras 4 threads no bloco satisfarão a condição if [^12]. Os valores de índice calculados para essas threads serão 3, 7, 11 e 15 [^12]. Essas threads executarão a segunda linha de adições na Figura 9.5 [^12]. Observe que, como sempre usaremos threads consecutivas em cada iteração, o problema de divergência de controle não surge até que o número de threads ativas caia abaixo do tamanho do warp [^12].

A árvore de distribuição é um pouco mais complexa de implementar [^12]. Fazemos uma observação de que o valor do stride diminui de SECTION\\_SIZE/2 para 1 [^12]. Em cada iteração, precisamos "empurrar" o valor do elemento XY de uma posição que é um múltiplo do valor do stride menos 1 para uma posição que está a um stride de distância [^12]. Por exemplo, na Figura 9.5 [^12], o valor do stride diminui de 8 para 1 [^12]. Na primeira iteração na Figura 9.5 [^12], gostaríamos de empurrar o valor de XY[7] para XY[11], onde 7 é 8 – 1 [^12]. Na segunda iteração, gostaríamos de empurrar os valores de XY[3], XY[7] e XY[11] para XY[5], XY[9] e XY[13] [^12]. Isso pode ser implementado com o seguinte loop [^12]:

```c++
for (int stride = SECTION_SIZE/4; stride > 0; stride /= 2){
    _synchthreads();
    int index = (threadIdx.x + 1)*stride*2-1;
    if(index + stride < BLOCK_SIZE){
        XY[index + stride] += XY[index];
    }
}
```

### Conclusão
O algoritmo de scan paralelo work-efficient, utilizando uma árvore de redução, oferece uma alternativa mais eficiente em termos de trabalho em comparação com o algoritmo paralelo simples [^9]. A utilização de uma árvore de redução permite o compartilhamento de resultados intermediários e a minimização do número de operações, tornando-o mais adequado para aplicações com restrições de energia ou que exigem alta performance [^9]. No entanto, a complexidade adicional do algoritmo pode exigir uma análise cuidadosa para garantir o máximo desempenho em diferentes arquiteturas de hardware [^9].
O número de operações é (16/8) + 1 + (16/4) + (16/2) [^13]. Em geral, para N elementos de entrada, o número total de operações seria (N/2) + (N/4) +...+ 4 + 2 – 1, que é menor que N – 2 [^14]. Isso torna o número total de operações no scan paralelo 2 × N – 3 [^14]. Observe que o número de operações agora é proporcional a N, em vez de N × log₂(N) [^14].

### Referências
[^1]: Capítulo 9: Parallel Patterns: Prefix Sum - An Introduction to Work Efficiency in Parallel Algorithms
[^9]: Seção 9.4: A Work-Efficient Parallel Scan
[^10]: Figura 9.5 e 9.6
[^11]: Seção 9.4: A Work-Efficient Parallel Scan
[^12]: Seção 9.4: A Work-Efficient Parallel Scan
[^13]: Seção 9.4: A Work-Efficient Parallel Scan
[^14]: Seção 9.4: A Work-Efficient Parallel Scan
<!-- END -->