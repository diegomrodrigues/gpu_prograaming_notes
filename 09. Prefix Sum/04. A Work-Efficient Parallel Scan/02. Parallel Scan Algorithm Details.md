## 9.4 A Work-Efficient Parallel Scan: Reduction and Reverse Tree Algorithm

### Introdução
Enquanto o *kernel* paralelo simples apresentado na seção anterior (9.2) é conceitualmente direto, sua eficiência de trabalho é inadequada para muitas aplicações práticas [^205]. Analisando as Figuras 9.1 e 9.3 [^205], percebemos oportunidades potenciais para compartilhar resultados intermediários, otimizando as operações realizadas. Para ampliar o compartilhamento entre *threads*, é crucial calcular rapidamente os resultados intermediários e distribuí-los eficientemente entre as *threads* [^205]. Esta seção foca no algoritmo *work-efficient parallel scan*, que utiliza árvores de redução e reversão para otimizar o processo.

### Conceitos Fundamentais
A abordagem *work-efficient parallel scan* utiliza uma árvore de redução para calcular somas parciais e uma árvore reversa para distribuir essas somas parciais [^205]. Este método minimiza o número de operações necessárias para gerar a soma total e os subprodutos necessários para o *scan*.

**Árvore de Redução:**
A maneira mais rápida de produzir somas para um conjunto de valores é através de uma árvore de redução. Uma árvore de redução pode gerar a soma de *N* valores em log₂(N) passos [^205]. Além disso, a árvore pode gerar vários subprodutos que podem ser usados no cálculo de alguns dos valores de saída do *scan* [^205]. A Figura 9.5 [^205] ilustra a produção da soma de 16 elementos em quatro passos. Durante o primeiro passo, apenas os elementos ímpares de `XY[i]` são alterados para `xi-1 + xi` [^205]. Durante o segundo passo, apenas os elementos `XY` cujos índices são da forma `4 × n - 1` (3, 7, 11 e 15) são atualizados [^205]. No terceiro passo, somente os elementos `XY` cujos índices são da forma `8 × n - 1` (7 e 15) são atualizados. Finalmente, no quarto passo, apenas `XY[15]` é atualizado [^205]. O número total de operações realizadas é 8 + 4 + 2 + 1 = 15. Em geral, para uma seção de *scan* de *N* elementos, é realizado (N/2) + (N/4) + ... + 2 + 1 = N - 1 operações para esta fase de redução [^206].

**Árvore Reversa:**
A segunda parte do algoritmo utiliza uma árvore reversa para distribuir as somas parciais para as posições que podem usar esses valores o mais rápido possível [^206]. A Figura 9.5 [^206] ilustra isso na metade inferior. No final da fase de redução, existem algumas somas parciais utilizáveis. A primeira linha da Figura 9.6 [^206] mostra todas as somas parciais em `XY` logo após a árvore de redução superior. Uma observação importante é que `XY[0]`, `XY[7]` e `XY[15]` contêm suas respostas finais. Portanto, todos os elementos `XY` restantes podem obter as somas parciais de que precisam a não mais de quatro posições de distância [^206]. Por exemplo, `XY[14]` pode obter todas as somas parciais de que precisa de `XY[7]`, `XY[11]` e `XY[13]` [^206]. Para organizar a segunda metade das operações de adição, o algoritmo primeiro mostra todas as operações que precisam de somas parciais de quatro posições de distância, depois duas posições de distância e, em seguida, uma posição de distância [^207]. Por inspeção, `XY[7]` contém um valor crítico necessário para muitas posições na metade direita. Uma boa maneira é adicionar `XY[7]` a `XY[11]`, o que traz `XY[11]` para a resposta final [^207]. Mais importante ainda, `XY[7]` também se torna uma boa soma parcial para `XY[12]`, `XY[13]` e `XY[14]`. Nenhuma outra soma parcial tem tantos usos. Portanto, há apenas uma adição, `XY[11] = XY[7] + XY[11]`, que precisa ocorrer no nível de quatro posições na Figura 9.5 [^207].

### Implementação e Otimização
O *loop* para a fase de redução da árvore é semelhante ao usado na redução da Figura 6.2, exceto que o *thread* que realiza a adição é aquele com um índice da forma 2ⁿ-1, em vez de 2ⁿ [^207]. Isso é alcançado adicionando 1 a `threadIdx.x` ao selecionar os *threads* para adição em cada iteração [^207]. No entanto, esse estilo de redução é conhecido por ter problemas de divergência de controle. Uma maneira melhor de fazer isso é usar um número decrescente de *threads* contíguos para realizar as adições à medida que o *loop* avança [^208].

A árvore de distribuição é um pouco mais complexa de implementar [^208]. A cada iteração, o valor do elemento `XY` de uma posição que é um múltiplo do valor do passo menos 1 precisa ser "empurrado" para uma posição que está a um passo de distância [^208]. Por exemplo, na Figura 9.5 [^208], o valor do passo diminui de 8 para 1. Na primeira iteração na Figura 9.5 [^208], gostaríamos de empurrar o valor de `XY[7]` para `XY[11]`, onde 7 é 8 - 1. Na segunda iteração, gostaríamos de empurrar os valores de `XY[3]`, `XY[7]` e `XY[11]` para `XY[5]`, `XY[9]` e `XY[13]`.

Analisando o número de operações no estágio da árvore de distribuição, o número de operações é (16/8) + (16/4) + (16/2). Em geral, para *N* elementos de entrada, o número total de operações seria (N/2) + (N/4) +...+ 4 + 2 - 1, que é menor que N - 2 [^209, 210]. Isso torna o número total de operações no *scan* paralelo 2 × N - 3 [^210]. O número de operações é agora proporcional a N, em vez de N × log₂(N) [^210].

### Conclusão
O algoritmo *work-efficient parallel scan* oferece uma melhoria significativa em relação aos algoritmos mais simples. Ao utilizar árvores de redução e reversão, o algoritmo minimiza o número de operações necessárias, tornando-o mais adequado para aplicações práticas [^205]. A vantagem de um algoritmo *work-efficient* é bastante clara na comparação. À medida que a seção de entrada fica maior, o algoritmo *work-efficient* nunca executa mais do que duas vezes o número de operações executadas pelo algoritmo sequencial [^210]. Contanto que tenhamos pelo menos duas vezes mais recursos de execução de *hardware*, o algoritmo paralelo alcançará um desempenho melhor do que o algoritmo sequencial [^210]. Isso não é verdade, no entanto, para o algoritmo *work-inefficient*. Para 102 elementos, o algoritmo paralelo precisa de pelo menos nove vezes os recursos de execução de *hardware* apenas para atingir o ponto de equilíbrio [^210].

### Referências
[^205]: Seção 9.4, parágrafos 1-3
[^206]: Seção 9.4, parágrafos 4-5
[^207]: Seção 9.4, parágrafo 6
[^208]: Seção 9.4, parágrafos 7-8
[^209]: Seção 9.4, parágrafos 9
[^210]: Seção 9.4, parágrafo 10

<!-- END -->