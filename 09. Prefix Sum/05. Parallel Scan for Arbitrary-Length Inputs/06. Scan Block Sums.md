## Parallel Scan para Entradas de Comprimento Arbitrário: Soma dos Blocos de Scan

### Introdução
Expandindo sobre os conceitos de **parallel scan** e sua otimização para eficiência de trabalho, este capítulo aprofunda-se na aplicação de **parallel scan para entradas de comprimento arbitrário**, um cenário comum em muitas aplicações práticas [^1]. Anteriormente, exploramos algoritmos de **parallel scan** simples e eficientes em termos de trabalho, cada um com suas próprias características de desempenho e limitações [^9]. Agora, combinaremos esses conceitos para abordar conjuntos de dados que excedem os limites de memória compartilhada e do tamanho de bloco único, utilizando uma abordagem hierárquica [^14].

### Conceitos Fundamentais
A abordagem para **parallel scan** em entradas de comprimento arbitrário envolve uma estratégia hierárquica que particiona a entrada em seções menores, processáveis por um único bloco de threads [^14]. O conceito central reside no fato de que *o último elemento de saída de cada bloco de scan fornece a soma de todos os elementos de entrada desse bloco* [^15]. Esses valores são então coletados em um array, sobre o qual um **scan** é realizado.

**Passos Principais:**
1. **Particionamento:** A entrada é dividida em blocos de scan, cujo tamanho é determinado pelas limitações da memória compartilhada e do número de threads por bloco. Para dispositivos CUDA, o kernel eficiente em termos de trabalho em [^9] pode processar até 2.048 elementos por seção, utilizando 1.024 threads por bloco [^14].
2. **Scan Local:** Um **parallel scan** é executado em cada bloco individualmente. Após essa etapa, cada bloco contém os resultados do **scan** para seus elementos, sem considerar as contribuições dos blocos anteriores [^15].
3. **Soma dos Blocos:** O último elemento de cada bloco, que representa a soma de todos os elementos naquele bloco, é armazenado em um array auxiliar *S* [^15]. Este array *S* contém, portanto, as somas parciais de cada bloco [^15].
4. **Scan Global:** Um **parallel scan** é realizado sobre o array *S*. Os resultados deste **scan** representam as somas acumuladas dos blocos [^15].
5. **Ajuste Final:** Os resultados do **scan** global (array *S*) são então adicionados aos resultados locais de cada bloco correspondente. Isso garante que cada elemento no bloco tenha a soma correta de todos os elementos precedentes, tanto dentro do bloco quanto nos blocos anteriores [^17].

**Exemplo Ilustrativo:**
Considere um array de 16 elementos dividido em 4 blocos de 4 elementos cada [^16]. Após o **scan** local, o último elemento de cada bloco conterá a soma dos elementos desse bloco. Essas somas são então coletadas em um array *S*. Um **scan** sobre *S* produzirá somas acumuladas dos blocos. Finalmente, a soma acumulada correspondente de *S* é adicionada a cada elemento no bloco respectivo, corrigindo os resultados [^16].

**Implementação:**
A implementação envolve três kernels CUDA [^17]:

1. **Kernel de Scan Local:** Este kernel realiza o **parallel scan** dentro de cada bloco. O último thread de cada bloco escreve a soma do bloco no array *S* [^17].
2. **Kernel de Scan Global:** Este kernel executa o **parallel scan** no array *S* [^17].
3. **Kernel de Ajuste:** Este kernel adiciona os valores do array *S* (resultados do **scan** global) aos resultados do **scan** local em cada bloco [^17].

**Considerações de Trabalho:**
A abordagem hierárquica permite lidar com entradas de comprimento arbitrário sem sobrecarregar a memória compartilhada. No entanto, é essencial considerar a eficiência do trabalho. Embora cada bloco seja processado de forma eficiente, o overhead de gerenciar os kernels adicionais e transferir dados entre eles deve ser minimizado [^14].

### Conclusão
O **parallel scan** para entradas de comprimento arbitrário oferece uma solução escalável para realizar operações de prefixo em grandes conjuntos de dados [^14]. Ao combinar o conceito de **scan** local eficiente com uma abordagem hierárquica, é possível superar as limitações de memória e obter um bom desempenho em sistemas paralelos [^15]. O uso de três kernels separados permite uma modularidade clara e facilita a otimização de cada etapa individualmente [^17]. Este método é análogo ao *carry look-ahead* em somadores de hardware modernos, ressaltando a relevância e aplicabilidade do conceito [^17].

### Referências
[^1]: Capítulo 9, "Parallel Patterns: Prefix Sum"
[^9]: Seção 9.4, "A Work-Efficient Parallel Scan"
[^14]: Seção 9.5, "Parallel Scan for Arbitrary-Length Inputs"
[^15]: Seção 9.5, "Parallel Scan for Arbitrary-Length Inputs"
[^16]: Figura 9.10, "An example of a hierarchical scan."
[^17]: Seção 9.5, "Parallel Scan for Arbitrary-Length Inputs"
<!-- END -->