## 9.5 Parallel Scan para Entradas de Comprimento Arbitrário

### Introdução
Em continuidade ao desenvolvimento de algoritmos de *parallel scan*, este capítulo aborda a extensão desses algoritmos para lidar com entradas de comprimento arbitrário, um requisito crucial para aplicações práticas que frequentemente operam em conjuntos de dados massivos. Como visto anteriormente, os algoritmos de *parallel scan* são fundamentais para transformar operações aparentemente sequenciais em computações paralelas, otimizando o desempenho em uma variedade de aplicações [^1]. Este capítulo explora uma abordagem hierárquica que permite processar conjuntos de dados que excedem a capacidade da memória compartilhada, garantindo a eficiência e a escalabilidade dos algoritmos de *parallel scan* [^14].

### Conceitos Fundamentais
Para muitas aplicações, o número de elementos a serem processados por uma operação de *scan* pode ser da ordem de milhões [^14]. Obviamente, não podemos esperar que todos os elementos de entrada caibam na memória compartilhada [^14]. Além disso, seria uma perda de oportunidade de paralelismo se usássemos apenas um bloco de *threads* para processar esses grandes conjuntos de dados [^14]. Felizmente, existe uma abordagem hierárquica para estender os *kernels* de *scan* que geramos até agora para lidar com entradas de tamanho arbitrário [^14]. A abordagem é ilustrada na Figura 9.9 [^14].

Para um grande conjunto de dados, primeiro particionamos a entrada em seções que podem caber na memória compartilhada e são processadas por um único bloco [^14]. Para a geração atual de dispositivos CUDA, o *kernel work-efficient* na Figura 9.8 pode processar até 2.048 elementos em cada seção usando 1.024 *threads* em cada bloco [^14]. Por exemplo, se os dados de entrada consistem em 2.000.000 de elementos, podemos usar $\\lceil 2.000.000/2048 \\rceil = 977$ blocos de *threads* [^14]. Com até 65.536 blocos de *threads* na dimensão x de uma *grid*, a abordagem pode processar até 134.217.728 elementos no conjunto de entrada [^15].

A Figura 9.10 mostra um pequeno exemplo operacional da abordagem de *scan* hierárquico da Figura 9.9 [^16]. Neste exemplo, existem 16 elementos de entrada que são divididos em quatro blocos de *scan* [^16]. O *kernel* trata os quatro blocos de *scan* como conjuntos de dados de entrada independentes [^16]. Depois que o *kernel* de *scan* termina, cada elemento Y contém o resultado do *scan* com seu bloco de *scan* [^16]. Por exemplo, o bloco de *scan* 1 tem entradas 0, 4, 1, 2 [^16]. O *kernel* de *scan* produz o resultado do *scan* para esta seção (0, 4, 5, 7) [^16]. Observe que esses resultados não contêm as contribuições de nenhum dos elementos no bloco de *scan* 0 [^16]. Para produzir o resultado final para este bloco de *scan*, a soma de todos os elementos no bloco de *scan* 0 ($2 + 1 + 3 + 1 = 7$) deve ser adicionada a cada elemento de resultado do bloco de *scan* 1 [^16].

Para outro exemplo, as entradas no bloco de *scan* 2 são 0, 3, 1, e 2 [^16]. O *kernel* produz o resultado do *scan* para este bloco de *scan* (0, 3, 4, 6) [^16]. Para produzir os resultados finais para este bloco de *scan*, a soma de todos os elementos em ambos os blocos de *scan* 0 e 1 ($2 + 1 + 3 + 1 + 0 + 4 + 1 + 2 = 14$) deve ser adicionada a cada elemento de resultado do bloco de *scan* 2 [^16].

É importante notar que o último elemento de saída do *scan* de cada bloco de *scan* fornece a soma de todos os elementos de entrada do bloco de *scan* [^16]. Esses valores são 7, 7, 6, e 11 na Figura 9.10 [^16]. Isso nos leva ao segundo passo do algoritmo de *scan* hierárquico na Figura 9.9, que reúne os últimos elementos de resultado de cada bloco de *scan* em um *array* e realiza um *scan* sobre estes elementos [^16].

Este passo também é ilustrado na Figura 9.10, onde os últimos elementos de saída do *scan* são todos coletados em um novo *array* S [^17]. Isto pode ser feito mudando o código no final do *kernel* de *scan* de forma que a última *thread* de cada bloco escreva seu resultado em um *array* S usando seu `blockIdx.x` como o índice [^17]. Uma operação de *scan* é então realizada em S para produzir valores de saída 7, 14, 20, e 31 [^17]. Note que cada um destes valores de saída de *scan* de segundo nível são a soma acumulada desde a localização inicial $X[0]$ até o final de cada bloco de *scan* [^17]. Ou seja, o valor de saída em $S[0] = 7$ é a soma acumulada de $X[0]$ até o final do bloco de *scan* 0, que é $X[3]$ [^17]. O valor de saída em $S[1] = 14$ é a soma acumulada de $X[0]$ até o final do bloco de *scan* 1, que é $X[7]$ [^17].

Portanto, os valores de saída no *array* S dão os resultados do *scan* em localizações "estratégicas" do problema de *scan* original [^17]. Ou seja, na Figura 9.10, os valores de saída em $S[0]$, $S[1]$, $S[2]$, e $S[3]$ dão os resultados finais do *scan* para o problema original nas posições $X[3]$, $X[7]$, $X[11]$, e $X[15]$ [^17]. Estes resultados podem ser usados para trazer os resultados parciais em cada bloco de *scan* para seus valores finais [^17]. Isto nos leva ao último passo do algoritmo de *scan* hierárquico na Figura 9.9 [^17]. Os valores de saída de *scan* de segundo nível são adicionados aos valores de seus blocos de *scan* correspondentes [^17].

Por exemplo, na Figura 9.10, o valor de $S[0]$ (7) será adicionado a $Y[0]$, $Y[1]$, $Y[2]$, e $Y[3]$ do bloco de *thread* 1, o que completa os resultados nestas posições [^17]. Os resultados finais nestas posições são 7, 11, 12, e 14 [^17]. Isto ocorre porque $S[0]$ contém a soma dos valores da entrada original $X[0]$ até $X[3]$ [^17]. Estes resultados finais são 14, 17, 18, e 20 [^17]. O valor de $S[1]$ (14) será adicionado a $Y[8]$, $Y[9]$, $Y[10]$, e $Y[11]$, o que completa os resultados nestas posições [^17]. O valor de $S[2]$ será adicionado a $S[2]$ (20), que será adicionado a $Y[12]$, $Y[13]$, $Y[14]$, e $Y[15]$ [^17]. Finalmente, o valor de $S[3]$ é a soma de todos os elementos da entrada original, que também é o resultado final em $Y[15]$ [^17].

Podemos implementar o *scan* hierárquico com três *kernels* [^17]. O primeiro *kernel* é amplamente o mesmo que o *kernel* na Figura 9.7 [^17]. Precisamos adicionar mais um parâmetro S, que tem a dimensão de `InputSize/SECTION_SIZE` [^17]. No final do *kernel*, adicionamos uma declaração condicional para que a última *thread* no bloco escreva o valor de saída do último elemento XY no bloco de *scan* para a posição `blockIdx.x` de S [^17]:

```c++
__synchtrheads();
if (threadIdx.x == 0) {
    S[blockIdx.x] = XY[SECTION_SIZE - 1];
}
```

O segundo *kernel* é simplesmente o mesmo *kernel* da Figura 9.7, que recebe S como entrada e escreve S como saída [^17].

O terceiro *kernel* recebe os *arrays* S e Y como entradas e escreve a saída de volta em Y [^18]. O corpo do *kernel* adiciona um dos elementos S a todos os elementos Y [^18]:

```c++
int i = blockIdx.x * blockDim.x + threadIdx.x;
Y[i] += S[blockIdx.x];
```

Deixamos como exercício para os leitores completarem os detalhes de cada *kernel* e completarem o código *host* [^18].

### Conclusão
Este capítulo apresentou uma abordagem hierárquica para estender os algoritmos de *parallel scan* para conjuntos de dados de tamanho arbitrário [^14]. Ao particionar a entrada em seções que podem ser processadas por um único bloco e, em seguida, combinar os resultados usando uma abordagem de dois níveis, podemos lidar com conjuntos de dados que excedem a capacidade da memória compartilhada [^14, 15]. Essa abordagem garante que os algoritmos de *parallel scan* permaneçam eficientes e escaláveis, mesmo para as maiores entradas [^14].

### Referências
[^1]: Capítulo 9: Parallel Patterns: Prefix Sum - Introdução à eficiência de trabalho em algoritmos paralelos.
[^14]: Seção 9.5: Parallel Scan for Arbitrary-Length Inputs.
[^15]: Seção 9.5: Parallel Scan for Arbitrary-Length Inputs.
[^16]: Seção 9.5: Parallel Scan for Arbitrary-Length Inputs.
[^17]: Seção 9.5: Parallel Scan for Arbitrary-Length Inputs.
[^18]: Seção 9.5: Parallel Scan for Arbitrary-Length Inputs.
<!-- END -->