## Kernel Implementation for a Simple Parallel Scan

### Introdução
Este capítulo detalha a implementação de um kernel para realizar um *scan* paralelo simples, conforme apresentado na seção 9.2 [^4, ^5]. O *scan* paralelo é uma operação fundamental em computação paralela, permitindo a conversão de operações aparentemente sequenciais em operações paralelas. Este capítulo se concentrará na implementação de um kernel CUDA específico para realizar um *scan* em uma seção do *array* de entrada, com ajustes para *arrays* de entrada maiores.

### Conceitos Fundamentais
A implementação do algoritmo envolve atribuir cada *thread* para evoluir o conteúdo de um elemento XY [^5]. Um *kernel* é escrito para executar um *scan* em uma seção da entrada que é pequena o suficiente para um bloco lidar. O tamanho da seção é definido como uma constante de tempo de compilação `SECTION_SIZE` [^5].

O *kernel* é lançado com `SECTION_SIZE` como o tamanho do bloco, garantindo um número igual de *threads* e elementos da seção [^5]. Todos os resultados são calculados como se o *array* contivesse apenas os elementos da seção, com ajustes finais para *arrays* de entrada maiores [^5].

A implementação do *kernel* envolve os seguintes passos:
1.  Cada *thread* executa um *scan* em uma seção da entrada, cujo tamanho é definido pela constante `SECTION_SIZE` [^5].
2.  O *kernel* é lançado com um número de *threads* igual a `SECTION_SIZE`, garantindo que cada *thread* processe um elemento da seção [^5].

O código CUDA para o *kernel* é apresentado a seguir [^6]:

```c++
__global__ void work_inefficient_scan_kernel(float *X, float *Y, int InputSize){
    __shared__ float XY[SECTION_SIZE];
    int i = blockIdx.x*blockDim.x + threadIdx.x;
    if (i < InputSize) {
        XY[threadIdx.x] = X[i];

        // the code below performs iterative scan on XY
        for (unsigned int stride = 1; stride <= threadIdx.x; stride *= 2){
            __syncthreads();
            XY[threadIdx.x] += XY[threadIdx.x-stride];
        }

        Y[i] = XY[threadIdx.x];
    }
}
```

O *kernel* `work_inefficient_scan_kernel` recebe como entrada um *array* de entrada `X`, um *array* de saída `Y` e o tamanho da entrada `InputSize` [^6]. Cada *thread* calcula sua posição no *array* de entrada usando `blockIdx.x`, `blockDim.x` e `threadIdx.x` [^6]. Se a posição calculada estiver dentro dos limites do *array* de entrada, a *thread* carrega o elemento correspondente do *array* de entrada para o *array* de memória compartilhada `XY` [^6].

O *loop* interno itera através da árvore de redução para a posição do *array* XY que é atribuída a uma *thread* [^6]. Uma sincronização de barreira é usada para garantir que todas as *threads* tenham terminado sua iteração atual de adições na árvore de redução antes que qualquer uma delas comece a próxima iteração [^6]. Quando o valor de `stride` se torna maior que o valor `threadIdx.x` de uma *thread*, significa que a posição XY atribuída à *thread* já acumulou todos os valores de entrada necessários [^6]. Assim, a *thread* pode sair do *loop while* [^6].

Finalmente, cada *thread* escreve seu resultado no *array* de saída `Y` [^6].

### Conclusão
Este capítulo detalhou a implementação de um *kernel* CUDA para realizar um *scan* paralelo simples [^5, ^6]. O *kernel* funciona dividindo a entrada em seções, realizando um *scan* em cada seção em paralelo e, em seguida, combinando os resultados [^5]. Embora este *kernel* seja conceitualmente simples, ele não é muito eficiente em termos de trabalho, pois executa mais adições do que o algoritmo sequencial [^8]. No entanto, serve como um ponto de partida para entender algoritmos de *scan* paralelos mais complexos e eficientes, como o *scan* paralelo eficiente em termos de trabalho, que será abordado em capítulos subsequentes [^9].

### Referências
[^4]: Capítulo 9, página 197
[^5]: Capítulo 9, página 201
[^6]: Capítulo 9, página 202
[^8]: Capítulo 9, página 204
[^9]: Capítulo 9, página 205
<!-- END -->