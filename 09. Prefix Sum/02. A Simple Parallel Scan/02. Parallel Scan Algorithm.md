## In-Place Parallel Scan Algorithm

### Introdução
Este capítulo se aprofunda no conceito de **parallel scan**, também conhecido como **prefix sum**, uma ferramenta fundamental na computação paralela. Como vimos anteriormente, o *parallel scan* converte operações sequenciais em operações paralelas, otimizando a alocação de recursos e a avaliação de polinômios [^1]. Este capítulo focará em um algoritmo *in-place parallel scan* simples, que opera diretamente no array de entrada [^4].

### Conceitos Fundamentais

O algoritmo *in-place parallel scan* opera em um array `XY`, que contém os elementos de entrada [^4]. A ideia central é que, a cada iteração, o array `XY` evolui para conter as somas parciais [^4]. Especificamente, na iteração *n*, `XY[i]` contém a soma de $2^n$ elementos de entrada até a posição *i* [^4]. Cada *thread* é responsável por evoluir o conteúdo de um elemento do array `XY` [^4].

**Funcionamento Detalhado:**

1.  **Inicialização:** Inicialmente, `XY[i]` contém o elemento de entrada $x_i$ [^4].
2.  **Iterações:** Após *n* iterações, `XY[i]` conterá a soma de $2^n$ elementos de entrada até a posição *i* [^4]. Ou seja, `XY[i]` irá conter $x_{i-2^n+1} + x_{i-2^n+2} + ... + x_i$.
3.  **Operação In-Place:** O algoritmo modifica o array de entrada diretamente, armazenando os resultados do *scan* iterativamente no mesmo espaço de memória [^4].
4.  **Responsabilidade das Threads:** Cada *thread* é responsável por evoluir o conteúdo de um único elemento do array `XY` [^4].

**Exemplo:**

Considere um array de entrada de 16 elementos, como ilustrado na Figura 9.1 [^4]. Cada linha vertical representa um elemento do array `XY`, com `XY[0]` na posição mais à esquerda [^5]. A direção vertical mostra o progresso das iterações, começando do topo da figura [^5].

*   **Iteração 1:** Cada posição, exceto `XY[0]`, recebe a soma de seu conteúdo atual e o de seu vizinho à esquerda [^5]. Assim, `XY[i]` conterá $x_{i-1} + x_i$ [^5].
*   **Iteração 2:** Cada posição, exceto `XY[0]` e `XY[1]`, recebe a soma de seu conteúdo atual e o da posição que está a dois elementos de distância [^5]. Como resultado, `XY[i]` agora contém $x_{i-3} + x_{i-2} + x_{i-1} + x_i$ [^5].

É importante notar que, após cada iteração, alguns elementos de `XY` contêm seus resultados finais e não precisam ser alterados em iterações subsequentes [^5]. Por exemplo, após a primeira iteração, `XY[1]` é igual a $x_0 + x_1$, que é a resposta final para essa posição [^5].

**Implementação:**

O algoritmo pode ser implementado atribuindo cada *thread* à evolução do conteúdo de um elemento `XY` [^5]. Um *kernel* é escrito para realizar o *scan* em uma seção da entrada que é pequena o suficiente para um bloco manipular [^5]. O tamanho dessa seção é definido como uma constante de tempo de compilação, `SECTION_SIZE` [^5]. Assume-se que o lançamento do *kernel* usará `SECTION_SIZE` como o tamanho do bloco, garantindo um número igual de *threads* e elementos da seção [^5].

O código abaixo performa o *scan* iterativo no array `XY` [^6]:

```c++
for (unsigned int stride = 1; stride <= threadIdx.x; stride *= 2) {
    __syncthreads();
    XY[threadIdx.x] += XY[threadIdx.x - stride];
}
```

Este *loop* itera através da árvore de redução para a posição do array `XY` que é atribuída a uma *thread* [^6]. A função `__syncthreads()` garante que todas as *threads* tenham terminado sua iteração atual de adições na árvore de redução antes que qualquer uma delas comece a próxima iteração [^6].

**Considerações sobre a Eficiência do Trabalho:**

O *kernel* *work-inefficient parallel scan* itera até $log(N)$ passos, onde *N* é o `SECTION_SIZE` [^8]. Em cada iteração, o número de *threads* que não precisam fazer nenhuma adição é igual ao tamanho do *stride* [^8]. Portanto, o número total de operações de adição é dado por:

$$\
\sum_{stride=1}^{N/2} (N - stride) = N \cdot log_2(N) - (N - 1)
$$

Comparado com um algoritmo *sequential scan* que requer *N-1* adições, o algoritmo *work-inefficient parallel scan* realiza significativamente mais trabalho [^8].

### Conclusão

O algoritmo *in-place parallel scan* oferece uma abordagem simples para a computação do *prefix sum* em paralelo [^4]. Apesar de sua simplicidade conceitual, a versão básica pode ser *work-inefficient* [^9]. O capítulo 9.4 apresenta um algoritmo *work-efficient parallel scan* que minimiza o número de operações e melhora o desempenho, especialmente para grandes conjuntos de dados [^9]. O uso de *reduction trees* e *distribution trees* permite um melhor compartilhamento de resultados intermediários e uma execução mais eficiente do *scan* paralelo [^9].

### Referências
[^1]: Capítulo 9: Parallel Patterns: Prefix Sum - An Introduction to Work Efficiency in Parallel Algorithms.
[^4]: Seção 9.2: A Simple Parallel Scan.
[^5]: Seção 9.2: A Simple Parallel Scan.
[^6]: Seção 9.2: A Simple Parallel Scan.
[^8]: Seção 9.3: Work Efficiency Considerations.
[^9]: Seção 9.4: A Work-Efficient Parallel Scan.
<!-- END -->