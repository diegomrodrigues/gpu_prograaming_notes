## Análise Comparativa com o Algoritmo Sequencial

### Introdução
Em "Work Efficiency Considerations", é crucial analisar a eficiência de um algoritmo paralelo em relação ao seu equivalente sequencial. Esta análise revela as vantagens e desvantagens de cada abordagem, especialmente em termos de uso de hardware e consumo de energia. O algoritmo de *scan* (prefix sum) é frequentemente utilizado para converter operações sequenciais em paralelas [^1]. Este capítulo se aprofunda na comparação entre o algoritmo de *scan* paralelo simples apresentado na seção 9.2 [^1] e o algoritmo sequencial.

### Comparação com o Algoritmo Sequencial

O algoritmo sequencial para o *scan* inclusivo realiza apenas $N - 1$ operações de adição, onde $N$ é o número de elementos de entrada [^1]. A implementação do algoritmo sequencial é mostrada na página 199 [^3]:
```c++
void sequential_scan(float *x, float *y, int Max_i){
    y[0] = x[0];
    for (int i = 1; i < Max_i;i++){
        y[i] = y [i-1] + x[i];
    }
}
```
Este algoritmo é *work-efficient*, utilizando apenas uma adição, um carregamento de memória e um armazenamento de memória para cada elemento de entrada [^3].

Em contraste, o *kernel* paralelo simples, apresentado na seção 9.2 [^4], realiza um número significativamente maior de operações. Todos os *threads* iteram até $log_2(N)$ passos, onde $N$ é SECTION_SIZE. Em cada iteração, o número de *threads* que não precisam realizar nenhuma adição é igual ao tamanho do *stride* [^8].  Portanto, o número total de operações de adição para o algoritmo paralelo é dado por:

$$ \sum(N - stride), \text{ para } strides = 1, 2, 4, ..., N/2 \text{ (log2(N) terms)} $$

Isso se simplifica para:

$$ N \cdot log_2(N) - (N - 1) $$

Comparando este resultado com o algoritmo sequencial, que executa $N-1$ adições, fica evidente que o *kernel* paralelo executa muito mais trabalho, mesmo para tamanhos de seção modestos [^8]. Por exemplo, para $N = 1024$, o *kernel* realiza nove vezes mais trabalho que o código sequencial [^8]. Esta diferença se agrava à medida que $N$ aumenta [^8].

Esta ineficiência no trabalho do *kernel* paralelo levanta duas questões principais [^8]:

1.  **Uso de Hardware:** O uso do *hardware* para executar o *kernel* paralelo é menos eficiente. Para que o desempenho do *kernel* paralelo sequer se iguale ao do algoritmo sequencial, é necessário um número significativamente maior de unidades de execução na máquina paralela [^8]. Por exemplo, para 1024 elementos, seriam necessárias pelo menos nove vezes mais unidades de execução [^8].
2.  **Consumo de Energia:** O trabalho extra realizado pelo *kernel* paralelo consome energia adicional, o que o torna inadequado para ambientes com restrições de energia, como dispositivos móveis [^9].

A tabela abaixo (Figura 9.4 [^9]) ilustra a comparação do número de operações para diferentes valores de $N$:

| N                | 16  | 32  | 64  | 128 | 256  | 512  | 1024 |
| ---------------- | --- | --- | --- | --- | ---- | ---- | ---- |
| N-1              | 15  | 31  | 63  | 127 | 255  | 511  | 1023 |
| N*log2(N) – (N-1) | 49  | 129 | 321 | 769 | 1793 | 4097 | 9217 |

### Conclusão

A análise comparativa revela que, embora o algoritmo de *scan* paralelo simples seja conceitualmente fácil de entender, ele é significativamente menos eficiente em termos de trabalho do que o algoritmo sequencial [^8]. Esta ineficiência se traduz em maior uso de *hardware* e maior consumo de energia, tornando o *kernel* paralelo inadequado para certas aplicações [^8], [^9]. A seção 9.4 [^9] apresenta um algoritmo de *scan* paralelo mais eficiente em termos de trabalho, que visa mitigar essas desvantagens.

### Referências
[^1]: Capítulo 9, p. 197
[^3]: Capítulo 9, p. 199
[^4]: Capítulo 9, p. 200
[^8]: Capítulo 9, p. 204
[^9]: Capítulo 9, p. 205
<!-- END -->