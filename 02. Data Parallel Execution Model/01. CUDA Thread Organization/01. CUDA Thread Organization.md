## CUDA Thread Organization: Hierarchical Structure and Data Processing

### Introdução
Este capítulo explora a organização hierárquica dos *threads* em CUDA, um conceito fundamental para o desenvolvimento de aplicações de computação paralela de alto desempenho. Como vimos anteriormente no Capítulo 3, o lançamento de um *kernel* CUDA cria uma grade de *threads* que executam a mesma função [*kernel*] [^1]. Cada *thread* utiliza um índice único para identificar a porção de dados que deve processar [^1]. A organização dos *threads* em CUDA permite que cada um identifique a porção de dados a serem processados com base em suas coordenadas [^1]. Este capítulo detalha a organização, atribuição de recursos, sincronização e agendamento de *threads* em uma grade [^1].

### Conceitos Fundamentais

A organização dos *threads* em CUDA é hierárquica e consiste em *grids*, *blocks* e *threads* [^1, 2].
*   Um **grid** é composto por um ou mais *blocks* [^1, 2].
*   Cada **block** é composto por um ou mais *threads* [^1, 2].

Essa estrutura permite que os *threads* se organizem e colaborem na execução de tarefas paralelas.

**Variáveis Embutidas**
Em CUDA, variáveis como `gridDim`, `blockDim`, `blockIdx` e `threadIdx` são variáveis embutidas, pré-inicializadas pelo *runtime* CUDA e acessíveis dentro das funções *kernel* [^2]. Os programadores devem evitar usar essas variáveis para outros fins [^2].

#### Índices de Blocos e Threads
*   Os *threads* dentro de um mesmo *block* compartilham o mesmo índice de *block*, acessível através da variável `blockIdx` [^1, 2].
*   Cada *thread* possui um índice único dentro do *block*, acessível através da variável `threadIdx` [^1, 2].

Quando um *thread* executa uma função *kernel*, as referências às variáveis `blockIdx` e `threadIdx` retornam as coordenadas do *thread* [^2].

#### Dimensões da Grade e do Bloco
A organização exata de um *grid* é determinada pelos parâmetros de configuração de execução (dentro de `<<<` e `>>>`) da declaração de lançamento do *kernel* [^3]. O primeiro parâmetro de configuração especifica as dimensões do *grid* em número de *blocks*, enquanto o segundo especifica as dimensões de cada *block* em número de *threads* [^3]. Essas dimensões estão disponíveis como variáveis embutidas predefinidas `gridDim` e `blockDim` nas funções *kernel* [^2, 3]. Cada parâmetro é do tipo `dim3`, um struct C com três campos inteiros sem sinal, x, y e z [^3]. Esses três campos correspondem às três dimensões [^3]. Para *grids* e *blocks* 1D ou 2D, os campos de dimensão não utilizados devem ser definidos como 1 para maior clareza [^3].

Por exemplo, o seguinte código *host* pode ser usado para lançar a função *kernel* `vecAddKernel()` e gerar um *grid* 1D que consiste em 128 *blocks*, cada um consistindo de 32 *threads* [^3]. O número total de *threads* no *grid* é 128 × 32 = 4.096 [^3].

```c++
dim3 dimBlock(32,1,1);
dim3 dimGrid(128,1,1);
vecAddKernel << <dimGrid, dimBlock >> > (...);
```

Note que `dimBlock` e `dimGrid` são variáveis de código *host* definidas pelo programador [^3]. Essas variáveis podem ter nomes, desde que sejam do tipo `dim3`, e o lançamento do *kernel* use os nomes apropriados [^3]. Por exemplo, as seguintes declarações realizam o mesmo que as declarações anteriores [^3]:

```c++
dim3 dog(32,1,1);
dim3 cat(128,1,1);
vecAddKernel<<<cat, dog >>> (...);
```

As dimensões do *grid* e do *block* também podem ser calculadas a partir de outras variáveis [^3]. Por exemplo, o lançamento do *kernel* na Figura 3.14 pode ser escrito como [^3]:

```c++
dim3 dimGrid(ceil(n/256.0),1,1);
dim3 dimBlock(256,1,1);
vecAddKernel << <dimGrid, dimBlock >> > (...);
```

Isso permite que o número de *blocks* varie com o tamanho dos vetores, de modo que o *grid* terá *threads* suficientes para cobrir todos os elementos do vetor [^3]. O valor da variável `n` no tempo de lançamento do *kernel* determinará a dimensão do *grid* [^3]. Se `n` for igual a 1.000, o *grid* consistirá em quatro *blocks* [^3]. Se `n` for igual a 4.000, o *grid* terá 16 *blocks* [^3]. Em cada caso, haverá *threads* suficientes para cobrir todos os elementos do vetor [^3]. Uma vez que `vecAddKernel()` é lançado, as dimensões do *grid* e do *block* permanecerão as mesmas até que todo o *grid* termine a execução [^3].

Para conveniência, CUDA C fornece um atalho especial para lançar um *kernel* com *grids* e *blocks* 1D [^3]. Em vez de usar variáveis `dim3`, pode-se usar expressões aritméticas para especificar a configuração de *grids* e *blocks* 1D [^4]. Nesse caso, o compilador CUDA C simplesmente considera a expressão aritmética como as dimensões x e assume que as dimensões y e z são 1 [^4]. Isso nos dá a declaração de lançamento do *kernel* mostrada na Figura 3.14 [^4]:

```c++
vecAddKernel << < ceil(n/256.0), 256>>>(...);
```

Dentro da função *kernel*, o campo x das variáveis predefinidas `gridDim` e `blockDim` é pré-inicializado de acordo com os parâmetros de configuração de execução [^4]. Por exemplo, se n for igual a 4.000, as referências a `gridDim.x` e `blockDim.x` na função *kernel* `vectAddkernel` resultarão em 16 e 256, respectivamente [^4]. Observe que, ao contrário das variáveis `dim3` no código *host*, os nomes dessas variáveis dentro das funções *kernel* fazem parte da especificação CUDA C e não podem ser alterados [^4]. Ou seja, as variáveis `gridDim` e `blockDim` na função *kernel* sempre refletem as dimensões do *grid* e dos *blocks* [^4].

Em CUDA C, os valores permitidos de `gridDim.x`, `gridDim.y` e `gridDim.z` variam de 1 a 65.536 [^4]. Todos os *threads* em um *block* compartilham os mesmos valores de `blockIdx.x`, `blockIdx.y` e `blockIdx.z` [^4]. Entre todos os *blocks*, o valor de `blockIdx.x` varia entre 0 e `gridDim.x-1`, o valor de `blockIdx.y` varia entre 0 e `gridDim.y-1`, e o valor de `blockIdx.z` varia entre 0 e `gridDim.z-1` [^4]. Para o resto deste livro, usaremos a notação (x, y, z) para um *grid* 3D com x *blocks* na direção x, y *blocks* na direção y e z *blocks* na direção z [^4].

Agora voltamos nossa atenção para a configuração de *blocks* [^4]. Os *blocks* são organizados em *arrays* 3D de *threads* [^4]. *Blocks* bidimensionais podem ser criados definindo a dimensão z como 1 [^4]. *Blocks* unidimensionais podem ser criados definindo as dimensões y e z como 1, como no exemplo `vectorAddkernel` [^4]. Como mencionamos antes, todos os *blocks* em um *grid* têm as mesmas dimensões [^4]. O número de *threads* em cada dimensão de um *block* é especificado pelo segundo parâmetro de configuração de execução no lançamento do *kernel* [^4]. Dentro do *kernel*, este parâmetro de configuração pode ser acessado como os campos x, y e z da variável predefinida `blockDim` [^4]. O tamanho total de um *block* é limitado a 1.024 *threads*, com flexibilidade na distribuição desses elementos nas três dimensões, desde que o número total de *threads* não exceda 1.024 [^4]. Por exemplo, (512, 1, 1), (8, 16, 4) e (32, 16, 2) são todos os valores de `blockDim` permitidos, mas (32, 32, 2) não é permitido, pois o número total de *threads* excederia 1.024 [^4].

Observe que o *grid* pode ter maior dimensionalidade do que seus *blocks* e vice-versa [^4]. Por exemplo, a Figura 4.1 mostra um pequeno exemplo de brinquedo de um *grid* 2D [^4].

#### Hierarquias em Sistemas Reais
A organização hierárquica dos *threads* em CUDA oferece uma forma de localidade, similar a sistemas do mundo real como o sistema telefônico dos EUA [^2]. Assim como os *threads* em CUDA, muitos sistemas reais são organizados hierarquicamente [^2]. No sistema telefônico, "áreas" (códigos de área) contêm linhas telefônicas, onde cada linha tem um número local único [^2]. Essa estrutura preserva a localidade para chamadas dentro da mesma área [^2].

### Conclusão

A organização hierárquica dos *threads* em CUDA, composta por *grids*, *blocks* e *threads*, é fundamental para o desenvolvimento de aplicações paralelas eficientes [^1, 2]. A utilização das variáveis embutidas `blockIdx` e `threadIdx` permite que cada *thread* identifique sua porção de dados a serem processados [^1, 2]. A flexibilidade na configuração das dimensões dos *grids* e *blocks*, juntamente com a localidade inerente à organização hierárquica, contribui para o alto desempenho das aplicações CUDA [^3, 2].

### Referências
[^1]: Página 63 do texto fornecido.
[^2]: Página 64 do texto fornecido.
[^3]: Página 65 do texto fornecido.
[^4]: Página 66 do texto fornecido.
<!-- END -->