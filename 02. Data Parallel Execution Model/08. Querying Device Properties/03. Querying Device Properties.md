## Consultando Propriedades do Dispositivo

### Introdução
Em CUDA, a capacidade de consultar as propriedades do dispositivo é crucial para otimizar o desempenho da aplicação. Como visto no capítulo 3 e reiterado no início do capítulo 4 [^64], o CUDA organiza threads em uma hierarquia de grids e blocos. O número de threads, blocos e suas dimensões podem ser ajustados para melhor se adequarem à arquitetura do dispositivo de execução. Este capítulo explora como as aplicações podem interrogar o hardware subjacente para tomar decisões informadas sobre a alocação de recursos e a configuração da grade. Isso permite que as aplicações aproveitem ao máximo os sistemas mais capazes e, ao mesmo tempo, compensem os sistemas menos capazes [^85].

### Conceitos Fundamentais

**Necessidade de consulta de propriedades do dispositivo:**
A capacidade de consultar as propriedades do dispositivo surge da necessidade de executar aplicações em uma ampla variedade de sistemas de hardware [^85]. As aplicações devem ser capazes de se adaptar a diferentes números de SMs (Streaming Multiprocessors), limites de threads por bloco e tamanhos máximos de grade.

**API para consulta de propriedades:**
CUDA fornece um mecanismo integrado para que o código host consulte as propriedades dos dispositivos disponíveis no sistema [^86].
*   `cudaGetDeviceCount()`: Esta função retorna o número de dispositivos CUDA disponíveis no sistema [^86].
*   `cudaGetDeviceProperties()`: Esta função retorna as propriedades de um dispositivo específico, dado seu número como argumento [^86].

**Estrutura `cudaDeviceProp`:**
A função `cudaGetDeviceProperties()` preenche uma estrutura do tipo `cudaDeviceProp` com informações sobre o dispositivo [^86]. Esta estrutura contém vários campos que descrevem as propriedades do dispositivo, incluindo:

*   `maxThreadsPerBlock`: O número máximo de threads permitidos em um bloco no dispositivo consultado [^87].
*   `multiProcessorCount`: O número de SMs no dispositivo [^87].
*   `clockRate`: A frequência do clock do dispositivo [^87].
*   `maxThreadsDim[0]`, `maxThreadsDim[1]`, `maxThreadsDim[2]`: O número máximo de threads permitidos ao longo de cada dimensão (x, y, z) de um bloco [^87].
*   `maxGridSize[0]`, `maxGridSize[1]`, `maxGridSize[2]`: O número máximo de blocos permitidos ao longo de cada dimensão (x, y, z) de uma grade [^87].
*   `warpSize`: O tamanho do warp no dispositivo [^88].

**Exemplo de iteração e consulta de dispositivos:**
O código a seguir demonstra como iterar pelos dispositivos disponíveis e consultar suas propriedades [^86]:

```c++
int dev_count;
cudaGetDeviceCount( &dev_count);

cudaDeviceProp dev_prop;
for (int i = 0; i < dev_count; i++){
    cudaGetDeviceProperties( &dev_prop, i);
    // decide if device has sufficient resources and capabilities
}
```

**Tomada de decisão baseada em propriedades:**
As aplicações podem usar as propriedades do dispositivo consultadas para tomar decisões sobre a alocação de recursos e a configuração da grade [^86]. Por exemplo:

*   Se `dev_prop.maxThreadsPerBlock` for pequeno, a aplicação pode precisar usar blocos menores ou ajustar seu algoritmo para acomodar a limitação.
*   Se `dev_prop.multiProcessorCount` for baixo, a aplicação pode precisar reduzir o número de blocos ou usar técnicas para maximizar a utilização de cada SM.
*   As dimensões máximas de blocos e grades permitem que as aplicações determinem se uma grade pode lidar com todo o conjunto de dados ou se alguma forma de iteração é necessária [^87].

**Otimização e Autotuning:**
O autotuning é um processo em que um sistema de software itera através de diferentes valores de parâmetros (como `BLOCK_WIDTH` no exemplo de multiplicação de matrizes [^77]), compila e executa o código para o hardware de interesse, a fim de encontrar os melhores valores para esses parâmetros [^77]. A consulta de propriedades do dispositivo é fundamental para o autotuning, pois permite que o sistema defina os limites de pesquisa para parâmetros como as dimensões do bloco [^87].

**Warps e Escalonamento de Threads:**

Uma vez que um bloco é atribuído a um SM, ele é ainda dividido em unidades de 32 threads chamadas warps [^88]. O tamanho dos warps é específico da implementação [^88]. Em geral, existem menos SPs (hardware streaming processors) do que o número de threads atribuídos a cada SM [^88]. Em vez de executar todos os threads simultaneamente, o SM executa instruções de um pequeno subconjunto de todos os warps [^88]. Quando uma instrução executada pelos threads em um warp precisa esperar pelo resultado de uma operação de longa latência iniciada anteriormente, o warp não é selecionado para execução [^89]. Outro warp residente que não está mais esperando por resultados será selecionado para execução [^89]. Se mais de um warp estiver pronto para execução, um mecanismo de prioridade é usado para selecionar um para execução [^89]. Esse mecanismo de preenchimento do tempo de latência das operações com o trabalho de outros threads é frequentemente chamado de *tolerância à latência* ou *ocultação de latência* [^89].

### Conclusão

A capacidade de consultar as propriedades do dispositivo é essencial para escrever aplicações CUDA portáteis e de alto desempenho. Ao interrogar o hardware subjacente, as aplicações podem adaptar sua alocação de recursos e configuração de grade para maximizar a utilização e o desempenho. As propriedades do dispositivo, como o número máximo de threads por bloco, o número de SMs e as dimensões máximas da grade, fornecem informações valiosas que permitem que as aplicações tomem decisões informadas sobre como executar no hardware disponível. Este processo é fundamental para o autotuning e para alcançar a escalabilidade transparente em uma ampla gama de dispositivos CUDA [^83].

### Referências
[^64]: Capítulo 4 Introdução: "Fine-grained, data-parallel threads are the fundamental means of parallel execution in CUDA..."
[^85]: Seção 4.6: "In general, many modern applications are designed to execute on a wide variety of hardware systems. There is often a need for the application to query the available resources and capabilities of the underlying hardware to take advantage of the more capable systems while compensating for the less capable systems."
[^86]: Seção 4.6: "In CUDA C, there is a built-in mechanism for host code to query the properties of the devices available in the system. The CUDA runtime system has an API function `cudaGetDeviceCount()` that returns the number of available CUDA devices in the system... It provides an API function `cudaGetDeviceProperties()` that returns the properties of the device of which the number is given as an argument."
[^87]: Seção 4.6: "As the name suggests, the field `dev_prop.maxThreadsPerBlock` gives the maximal number of threads allowed in a block in the queried device... The host code can find the maximal number of threads allowed along each dimension of a block in `dev_prop.maxThreadsDim[0]` (for the x dimension)... Similarly, it can find the maximal number of blocks allowed along each dimension of a grid in `dev_prop.maxGridSize[0]` (for the x dimension)... A typical use of this information is to determine whether a grid can have enough threads to handle the entire data set or if some kind of iteration is needed."
[^88]: Seção 4.7: "implementations to date, once a block is assigned to a SM, it is further divided into 32-thread units called warps... The warp is the unit of thread scheduling in SMs."
[^89]: Seção 4.7: "When an instruction executed by the threads in a warp needs to wait for the result of a previously initiated long-latency operation, the warp is not selected for execution... This mechanism of filling the latency time of operations with work from other threads is often called latency tolerance or latency hiding."

<!-- END -->