## Otimização e Paralelização: Uma Abordagem de Computational Thinking

### Introdução
Este capítulo explora a interseção entre programação paralela e *computational thinking*, com foco em como a decomposição de problemas, a compreensão das características da arquitetura CUDA e a escolha de algoritmos adequados impactam a eficiência de aplicações paralelas [^1]. A combinação de conhecimento do domínio do problema e habilidades de *computational thinking* é crucial para criar soluções computacionais bem-sucedidas para problemas complexos [^1]. Este capítulo visa fornecer *insights* sobre programação paralela e *computational thinking* em geral [^1].

### Conceitos Fundamentais

#### Metas da Computação Paralela
Antes de mergulhar nos conceitos fundamentais da programação paralela, é essencial revisar as três principais motivações para adotar essa abordagem [^2]:

1.  **Redução do tempo de execução:** O objetivo primordial é resolver um determinado problema em menos tempo. Por exemplo, uma empresa de investimentos pode precisar executar uma análise de risco de cenário de portfólio financeiro em todos os seus portfólios durante o *after-trading hours*. Se essa análise levar 200 horas em um computador sequencial, mas o processo de gerenciamento de portfólio exigir que a análise seja concluída em quatro horas, a computação paralela pode acelerar a análise e permitir que ela seja concluída dentro do prazo necessário [^2].

2.  **Resolução de problemas maiores:** Outro objetivo é resolver problemas maiores dentro de um determinado período de tempo. No exemplo do portfólio financeiro, a empresa pode ser capaz de executar a análise de risco em seu portfólio atual dentro de um determinado período de tempo usando computação sequencial. No entanto, se a empresa planeja expandir o número de ativos em seu portfólio, o tamanho aumentado do problema fará com que o tempo de execução da análise sob computação sequencial exceda o período de tempo permitido. A computação paralela, ao reduzir o tempo de execução para o problema maior, pode acomodar a expansão planejada do portfólio [^2].

3.  **Obtenção de melhores soluções:** O terceiro objetivo é alcançar melhores soluções para um determinado problema em um determinado período de tempo. A empresa de investimento pode estar usando um modelo aproximado em sua análise de risco de cenário de portfólio. O uso de um modelo mais preciso pode aumentar a complexidade computacional e aumentar o tempo de execução em um computador sequencial além do período de tempo permitido. A computação paralela, ao reduzir o tempo de execução do modelo mais preciso, pode concluir a análise dentro do período de tempo permitido [^2].

Em suma, a computação paralela é motivada principalmente pelo aumento da velocidade, permitindo executar modelos existentes mais rapidamente, lidar com problemas maiores ou utilizar modelos mais complexos [^2].

#### Decomposição de Problemas
A decomposição de problemas é um passo crucial na programação paralela. Aplicações adequadas para computação paralela geralmente envolvem grandes volumes de dados e alta complexidade de modelagem [^3]. O problema deve ser formulado de forma a ser decomposto em subproblemas que possam ser resolvidos simultaneamente [^3].

*   **Arranjo de *threading*:** A forma como o trabalho de cálculo é dividido em unidades de execução paralela (threads em CUDA) é crucial e é referida como "arranjo de *threading*" [^4]. No problema de cálculo do mapa de potencial eletrostático, a decomposição pode ser *atom-centric* ou *grid-centric* [^4].

    *   Em um arranjo *atom-centric*, cada *thread* é responsável por calcular o efeito de um átomo em todos os pontos da grade [^4].
    *   Em um arranjo *grid-centric*, cada *thread* calcula o efeito de todos os átomos em um ponto da grade [^4].

Embora ambos os arranjos levem a níveis semelhantes de execução paralela, eles podem exibir desempenhos muito diferentes devido ao comportamento de acesso à memória [^4]. O arranjo *grid-centric* apresenta um comportamento de acesso à memória chamado *gather*, onde cada *thread* coleta os efeitos dos átomos de entrada em um ponto da grade. O *gather* é um arranjo desejável em dispositivos CUDA porque os *threads* podem acumular seus resultados em seus registradores privados, e vários *threads* podem compartilhar valores de átomos de entrada, utilizando *caching* de memória constante ou memória compartilhada para conservar a largura de banda da memória global [^4].

O arranjo *atom-centric*, por outro lado, exibe um comportamento de acesso à memória chamado *scatter*, onde cada *thread* espalha ou distribui o efeito de um átomo nos pontos da grade. O *scatter* é indesejável em dispositivos CUDA porque vários *threads* podem escrever no mesmo ponto da grade simultaneamente. Operações atômicas devem ser usadas para evitar condições de corrida e perda de valor durante escritas simultâneas em um ponto da grade por múltiplos *threads* [^5].

#### Seleção de Algoritmos
Um algoritmo é um procedimento passo a passo onde cada passo é precisamente declarado e pode ser executado por um computador [^7]. Um algoritmo deve exibir três propriedades essenciais:

*   **Definiteness:** Cada passo é precisamente declarado, sem espaço para ambiguidade [^7].
*   **Effective computability:** Cada passo pode ser realizado por um computador [^7].
*   **Finiteness:** O algoritmo deve ser garantido para terminar [^7].

Dado um problema, normalmente podemos apresentar vários algoritmos para resolver o problema [^7]. Alguns requerem menos etapas de computação do que outros; alguns permitem graus mais elevados de execução paralela do que outros; alguns têm melhor estabilidade numérica do que outros; e alguns consomem menos largura de banda de memória do que outros. Infelizmente, muitas vezes não existe um único algoritmo que seja melhor do que outros em todos os quatro aspectos. Dado um problema e uma estratégia de decomposição, um programador paralelo muitas vezes precisa selecionar um algoritmo que alcance o melhor compromisso para um determinado sistema de *hardware* [^7].

##### Estratégias de Algoritmos Agressivas: *Cutoff Binning*
Uma estratégia de algoritmo importante, conhecida como *cutoff binning*, pode melhorar significativamente a eficiência de execução de algoritmos de grade, sacrificando uma pequena quantidade de precisão [^8]. Essa estratégia é baseada na observação de que muitos problemas de cálculo de grade são baseados em leis físicas onde as contribuições numéricas de partículas ou amostras que estão longe de um ponto da grade podem ser tratadas coletivamente com um método implícito com uma complexidade computacional muito menor [^8].

No cálculo do potencial eletrostático, cada ponto da grade recebe contribuições de todos os átomos no algoritmo de soma direta [^8]. Embora essa abordagem seja muito paralela e obtenha excelente *speedup* sobre a execução somente na CPU para sistemas de grade de energia de tamanho moderado, ela não escala bem para sistemas de grade de energia muito grandes, onde o número de átomos aumenta proporcionalmente ao volume do sistema [^8].

O *cutoff binning* explora o fato de que cada ponto da grade precisa receber contribuições apenas de átomos próximos a ele [^8]. Os átomos que estão longe de um ponto da grade terão uma contribuição desprezível para o valor da energia no ponto da grade, pois a contribuição é inversamente proporcional à distância [^8].

A ideia principal do algoritmo é primeiro classificar os átomos de entrada em *bins* de acordo com suas coordenadas [^10]. Cada *bin* corresponde a uma caixa no espaço da grade e contém todos os átomos cuja coordenada cai na caixa [^10]. Um "vizinhança" de *bins* para um ponto da grade é a coleção de *bins* que contêm todos os átomos que podem contribuir para o valor da energia de um ponto da grade [^10].

### Conclusão
A elaboração de aplicações paralelas eficientes exige uma decomposição de alto nível do problema, uma compreensão clara dos comportamentos de acesso à memória desejáveis e indesejáveis em CUDA e a capacidade de tomar decisões criteriosas sobre esses aspectos. Os programadores paralelos enfrentam o desafio de projetar algoritmos que superem os desafios do paralelismo, eficiência de execução e consumo de largura de banda de memória, exigindo um conhecimento abrangente das técnicas algorítmicas [^1]. O processo de *computational thinking* é fundamental para navegar por essas complexidades e criar soluções eficazes [^13].

### Referências
[^1]: Capítulo 13, página 281.
[^2]: Capítulo 13, página 282.
[^3]: Capítulo 13, página 283.
[^4]: Capítulo 13, página 284.
[^5]: Capítulo 13, página 285.
[^7]: Capítulo 13, página 287.
[^8]: Capítulo 13, página 288.
[^10]: Capítulo 13, página 290.
[^13]: Capítulo 13, página 293.
<!-- END -->