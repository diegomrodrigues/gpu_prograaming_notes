## Amdahl's Law and Task-Level Parallelization in Problem Decomposition

### Introdução
Em continuidade ao capítulo sobre *Problem Decomposition* [^3], este capítulo se aprofunda na aplicação da Lei de Amdahl e na importância da paralelização em nível de tarefa para otimizar o desempenho de aplicações, especialmente em ambientes heterogêneos como CUDA e MPI. A decomposição eficaz de um problema é fundamental para aproveitar ao máximo as capacidades de computação paralela [^3]. A Lei de Amdahl impõe limitações ao *speedup* máximo alcançável através da paralelização, tornando crucial a identificação e minimização das partes sequenciais de uma aplicação [^2, 286]. Exploraremos como a paralelização em nível de tarefa e a exploração do paralelismo de dados em hierarquias, como em implementações MPI, podem mitigar o impacto das tarefas sequenciais [^2].

### Conceitos Fundamentais
A **Lei de Amdahl** [^2, 286] é uma ferramenta essencial para entender os limites do *speedup* que podem ser alcançados ao paralelizar uma aplicação. Ela afirma que o *speedup* de uma aplicação devido à computação paralela é limitado pela porção sequencial da aplicação [^2, 286]. Matematicamente, o *speedup* é dado por:

$$\
Speedup = \frac{1}{S + \frac{P}{N}}\
$$

Onde:
- $S$ é a fração do tempo de execução original que é inerentemente sequencial.
- $P$ é a fração do tempo de execução original que pode ser paralelizada ($P = 1 - S$).
- $N$ é o número de processadores.

**Exemplo Prático**
Considere uma aplicação onde 95% do tempo de execução original pode ser paralelizado e acelerado por um fator de 100x usando um dispositivo CUDA [^2, 286]. Os restantes 5% da aplicação permanecem sequenciais e são executados no *host*. O *speedup* da aplicação é:

$$\
Speedup = \frac{1}{0.05 + \frac{0.95}{100}} = \frac{1}{0.05 + 0.0095} = \frac{1}{0.0595} \approx 16.8\
$$

Mesmo com uma aceleração de 100x na porção paralelizável, o *speedup* geral da aplicação é limitado a aproximadamente 17x devido à porção sequencial [^2, 286]. Este exemplo ilustra a importância de minimizar o tempo de execução das atividades não paralelas para evitar gargalos de desempenho [^2].

**Paralelização em Nível de Tarefa**
A Lei de Amdahl motiva a **paralelização em nível de tarefa** [^2, 286]. Embora algumas atividades menores não justifiquem a execução paralela em *fine-grained*, pode ser vantajoso executá-las em paralelo com outras tarefas quando o conjunto de dados é grande o suficiente [^2, 286]. Isso pode ser alcançado usando um *host* *multicore* para executar essas tarefas em paralelo ou tentando executar simultaneamente vários *kernels* pequenos, cada um correspondendo a uma tarefa [^2, 286].

**Paralelismo de Dados Hierárquico com MPI e CUDA**
Uma abordagem alternativa para reduzir o efeito das tarefas sequenciais é explorar o **paralelismo de dados** de maneira hierárquica [^2, 286]. Em uma implementação MPI, uma aplicação de dinâmica molecular pode distribuir grandes blocos de *grids* espaciais e seus átomos associados para nós em um *cluster* de computação em rede [^2, 286]. Utilizando o *host* de cada nó para calcular a força vibracional e rotacional para seu bloco de átomos, é possível aproveitar múltiplos *CPUs* *host* para acelerar esses módulos menores [^2, 286]. Cada nó pode usar um dispositivo CUDA para calcular a força não ligada em um nível mais alto de *speedup* [^2, 287]. Os nós precisarão trocar dados para acomodar forças que atravessam blocos e átomos que se movem através dos limites dos blocos [^2, 287].

**Organização do Trabalho e Implementação em CUDA**
A organização do trabalho, como separar o cálculo das forças não ligadas em relação às forças vibracionais e rotacionais, impacta a decisão de implementar cada módulo em CUDA [^2, 285]. A quantidade de trabalho envolvida em cada módulo deve ser considerada [^2, 285]. O cálculo da força não ligada normalmente envolve interações entre muitos átomos e incorre em muito mais cálculos do que as forças vibracionais e rotacionais [^2, 285]. Portanto, esses módulos tendem a ser realizados como passagens separadas sobre a estrutura de dados da força [^2, 285]. O programador precisa decidir se cada passagem vale a pena implementar em um dispositivo CUDA [^2, 285]. Por exemplo, o programador pode decidir que os cálculos da força vibracional e rotacional não envolvem uma quantidade suficiente de trabalho para justificar a execução em um dispositivo [^2, 286]. Essa decisão levaria a um programa CUDA que lança um *kernel* que calcula forças não ligadas para todos os pontos da *grid*, enquanto continua a calcular as forças vibracionais e rotacionais para os pontos da *grid* no *host* [^2, 286].

### Conclusão
A Lei de Amdahl destaca a importância de equilibrar a paralelização com a minimização das partes sequenciais de uma aplicação [^2, 286]. A paralelização em nível de tarefa e a exploração do paralelismo de dados em hierarquias (MPI e CUDA) oferecem estratégias eficazes para mitigar o impacto das tarefas sequenciais e otimizar o desempenho em ambientes heterogêneos [^2, 286, 287]. A organização do trabalho e a consideração da quantidade de trabalho envolvida em cada módulo são cruciais para tomar decisões informadas sobre a implementação em CUDA [^2, 285]. Ao aplicar esses princípios, os desenvolvedores podem criar aplicações paralelas mais eficientes e escaláveis [^2, 286].

### Referências
[^2]: Página 281, Capítulo 13
[^3]: Página 283, Capítulo 13
[^285]: Página 285, Capítulo 13
[^286]: Página 286, Capítulo 13
[^287]: Página 287, Capítulo 13
<!-- END -->