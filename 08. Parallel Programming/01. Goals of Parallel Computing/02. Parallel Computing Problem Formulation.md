## Formulação e Decomposição de Problemas em Computação Paralela

### Introdução
A computação paralela visa otimizar a utilização dos recursos de hardware disponíveis para acelerar a resolução de problemas. Para que isso seja possível, é fundamental que os problemas sejam formulados e decompostos de maneira eficaz [^1]. Este capítulo se aprofundará no conceito de **problem decomposition**, explorando como ele se relaciona com os objetivos da computação paralela, como a redução do tempo de execução, o aumento do tamanho dos problemas que podem ser resolvidos e a obtenção de soluções mais precisas [^2]. A discussão incluirá exemplos práticos, como o problema de cálculo do potencial eletrostático, e abordará as considerações importantes para uma decomposição eficiente, como o **threading arrangement** e o **acesso à memória** [^4].

### Conceitos Fundamentais

A **formulação e decomposição eficaz de problemas** são essenciais para a computação paralela [^1]. Isso permite que os programadores desenvolvam código e organizem dados para resolver subproblemas simultaneamente, otimizando o uso dos recursos de hardware disponíveis [^1]. Este processo envolve dividir a carga de trabalho entre múltiplos processadores ou núcleos, permitindo que as tarefas sejam executadas simultaneamente e, assim, acelerando o processo de resolução [^1]. Também permite resolver problemas maiores dentro de um período de tempo aceitável, explorando a capacidade de distribuir a carga computacional em sistemas paralelos para lidar com conjuntos de dados massivos ou simulações complexas que seriam impraticáveis em sistemas sequenciais [^1]. Além disso, permite obter soluções mais precisas para um determinado problema dentro de um limite de tempo definido, utilizando a capacidade de realizar cálculos mais complexos e detalhados em paralelo, o que permite a incorporação de modelos mais sofisticados e a consideração de um número maior de variáveis, resultando em resultados mais confiáveis e refinados [^1].

A computação paralela é motivada principalmente pelo aumento da velocidade [^2]. Esse aumento de velocidade pode ser utilizado de três formas principais:
1.  Acelerar a execução de um modelo existente no tamanho atual do problema [^2].
2.  Acelerar a execução de um modelo existente em um problema de tamanho maior [^2].
3.  Acelerar a execução de um modelo mais complexo no tamanho atual do problema [^2].

A escolha de uma formulação e decomposição de problema adequadas impacta diretamente a eficiência da computação paralela. Aplicações que são boas candidatas para computação paralela tipicamente envolvem grandes tamanhos de problema e alta complexidade de modelagem [^3]. Isso significa que essas aplicações processam uma grande quantidade de dados, realizam muitas iterações nos dados, ou ambos [^3]. Para que tal problema seja resolvido com computação paralela, o problema deve ser formulado de tal forma que possa ser decomposto em subproblemas que podem ser resolvidos com segurança ao mesmo tempo [^3]. Sob tal formulação e decomposição, o programador escreve código e organiza dados para resolver esses subproblemas concorrentemente [^3].

A decomposição de um problema em unidades de execução paralela é crucial para utilizar o paralelismo inerente do problema [^4]. Por exemplo, no problema de cálculo do mapa de potencial eletrostático, é evidente que todos os átomos podem ser processados em paralelo e todos os pontos da grade de energia podem ser calculados em paralelo [^4]. No entanto, deve-se ter cuidado ao decompor o trabalho de cálculo em unidades de execução paralela, o que será referido como **threading arrangement** [^4]. A decomposição do problema de cálculo do mapa de potencial eletrostático pode ser atom-centric ou grid-centric [^4]. Em um **threading arrangement** atom-centric, cada thread é responsável por calcular o efeito de um átomo em todos os pontos da grade [^4]. Em contraste, um **threading arrangement** grid-centric usa cada thread para calcular o efeito de todos os átomos em um ponto da grade [^4].

Embora ambos os **threading arrangements** levem a níveis semelhantes de execução paralela e aos mesmos resultados de execução, eles podem exibir um desempenho muito diferente em um determinado sistema de hardware [^4]. O **threading arrangement** grid-centric tem um comportamento de acesso à memória chamado *gather*, onde cada thread reúne ou coleta o efeito de átomos de entrada em um ponto da grade [^4]. *Gather* é um **threading arrangement** desejável em dispositivos CUDA porque os threads podem acumular seus resultados em seus registradores privados [^4]. Além disso, vários threads compartilham valores de átomos de entrada e podem usar efetivamente o cache de memória constante ou memória compartilhada para conservar a largura de banda da memória global [^4].

O **threading arrangement** atom-centric, por outro lado, exibe um comportamento de acesso à memória chamado *scatter*, onde cada thread espalha ou distribui o efeito de um átomo em pontos da grade [^4]. Este é um arranjo indesejável em dispositivos CUDA porque os múltiplos threads podem escrever no mesmo ponto da grade ao mesmo tempo [^5]. Os pontos da grade devem ser armazenados em uma memória que pode ser escrita por todos os threads envolvidos [^5]. Operações atômicas devem ser usadas para prevenir condições de corrida e perda de valor durante escritas simultâneas em um ponto da grade por múltiplos threads [^5]. Essas operações atômicas são muito mais lentas do que os acessos de registrador usados no arranjo atom-centric [^5]. Compreender o comportamento do **threading arrangement** e as limitações do hardware permite que um programador paralelo direcione para o arranjo mais desejado baseado em *gather* [^5].

Uma aplicação real geralmente consiste em múltiplos módulos que trabalham juntos [^5]. O cálculo do mapa de potencial eletrostático é um desses módulos em aplicações de dinâmica molecular [^5]. Para cada átomo no sistema, a aplicação precisa calcular as várias formas de forças (e.g., vibracional, rotacional e não ligado) que são exercidas sobre o átomo [^5]. Cada forma de força é calculada por um método diferente [^5]. No nível mais alto, um programador precisa decidir como o trabalho é organizado [^5]. Note que a quantidade de trabalho pode variar dramaticamente entre esses módulos [^5]. O cálculo da força não ligada tipicamente envolve interações entre muitos átomos e incorre em muito mais cálculos do que as forças vibracionais e rotacionais [^5]. Portanto, esses módulos tendem a ser realizados como passes separados sobre a estrutura de dados da força [^5]. O programador precisa decidir se cada passe vale a pena implementar em um dispositivo CUDA [^5].

A porção de trabalho feita pelo dispositivo irá, em última análise, decidir a aceleração em nível de aplicação alcançada pela paralelização [^6]. Por exemplo, assuma que o cálculo da força não ligada representa 95% do tempo de execução sequencial original e é acelerado por 100× usando um dispositivo CUDA [^6]. Além disso, assuma que o resto da aplicação permanece no host e não recebe nenhuma aceleração [^6]. A aceleração em nível de aplicação é $1/(5\% + 95\%/100) = 1/(5\% + 0.95\%) = 1/(5.95\%) = 17\times$ [^6]. Esta é uma demonstração da Lei de Amdahl: a aceleração da aplicação devido à computação paralela é limitada pela porção sequencial da aplicação [^6]. Neste caso, mesmo que a porção sequencial da aplicação seja bastante pequena (5%), ela limita a aceleração em nível de aplicação para 17× mesmo que o cálculo da força não ligada tenha uma aceleração de 100× [^6]. Este exemplo ilustra um grande desafio na decomposição de grandes aplicações: o tempo de execução acumulado de pequenas atividades que não valem a pena a execução paralela em um dispositivo CUDA pode se tornar um fator limitante na aceleração vista pelos usuários finais [^6].

A Lei de Amdahl muitas vezes motiva a paralelização em nível de tarefa [^6]. Embora algumas dessas atividades menores não garantam a execução paralela massiva de grão fino, pode ser desejável executar algumas dessas atividades em paralelo umas com as outras quando o conjunto de dados é grande o suficiente [^6]. Isso poderia ser alcançado usando um host multicore para executar tais tarefas em paralelo [^6]. Alternativamente, poderíamos tentar executar simultaneamente múltiplos pequenos kernels, cada um correspondendo a uma tarefa [^6]. Os dispositivos CUDA anteriores não suportavam tal paralelismo, mas os novos dispositivos de geração, como o Kepler, suportam [^6].

Uma abordagem alternativa para reduzir o efeito de tarefas sequenciais é explorar o paralelismo de dados de uma maneira hierárquica [^6]. Por exemplo, em uma implementação de Message Passing Interface (MPI) [MPI2009], uma aplicação de dinâmica molecular normalmente distribuiria grandes blocos das grades espaciais e seus átomos associados para nós de um cluster de computação em rede [^6]. Ao usar o host de cada nó para calcular a força vibracional e rotacional para seu bloco de átomos, podemos aproveitar múltiplas CPUs de host para alcançar aceleração para esses módulos menores [^6]. Cada nó pode usar um dispositivo CUDA para calcular a força não ligada em um nível mais alto de aceleração [^7]. Os nós precisarão trocar dados para acomodar forças que atravessam blocos e átomos que se movem através dos limites dos blocos [^7].

### Conclusão
A formulação e decomposição de problemas são etapas cruciais no desenvolvimento de aplicações paralelas eficientes. A escolha de uma estratégia de decomposição adequada, considerando fatores como o **threading arrangement**, o acesso à memória e a Lei de Amdahl, pode impactar significativamente o desempenho da aplicação [^6]. A combinação de técnicas como **cutoff binning** [^8] e o uso de frameworks como MPI e CUDA [^7] podem levar a soluções de alto desempenho para problemas complexos.

### Referências
[^1]: Capítulo 13, página 281
[^2]: Capítulo 13, página 282
[^3]: Capítulo 13, página 283
[^4]: Capítulo 13, página 284
[^5]: Capítulo 13, página 285
[^6]: Capítulo 13, página 286
[^7]: Capítulo 13, página 287
[^8]: Capítulo 13, página 288
<!-- END -->