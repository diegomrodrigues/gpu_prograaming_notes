## Goals and Motivation for Parallel Computing

### Introdução
Este capítulo se concentra nos objetivos da computação paralela, destacando a motivação central por trás de seu uso. A computação paralela é adotada para resolver problemas em menos tempo, lidar com problemas maiores dentro de um limite de tempo aceitável e obter melhores soluções para problemas específicos dentro de um período limitado [^2].

### Conceitos Fundamentais

A motivação central por trás da computação paralela é aumentar a velocidade, seja para executar modelos existentes mais rapidamente, lidar com problemas maiores ou usar modelos mais complexos [^1]. Isso leva a análises mais rápidas e decisões mais ágeis [^1]. A computação paralela expande a capacidade de análise e modelagem, visando soluções mais precisas em um determinado período, utilizando modelos mais complexos e considerando mais fatores [^1].

A computação paralela pode ser impulsionada por uma combinação dos três objetivos mencionados anteriormente [^2]. No entanto, é fundamentalmente motivada pelo aumento da velocidade [^2]. O primeiro objetivo é alcançado ao aumentar a velocidade na execução do modelo existente no tamanho atual do problema [^2]. O segundo objetivo é alcançado ao aumentar a velocidade na execução do modelo existente em um tamanho de problema maior [^2]. O terceiro objetivo é alcançado ao aumentar a velocidade na execução de um modelo mais complexo no tamanho atual do problema [^2]. Obviamente, o aumento da velocidade por meio da computação paralela pode ser usado para alcançar uma combinação desses objetivos [^2]. Por exemplo, a computação paralela pode reduzir o tempo de execução de um modelo mais complexo em um tamanho de problema maior [^2].

A escolha de um algoritmo adequado é crucial na computação paralela. Um algoritmo é um procedimento passo a passo onde cada etapa é precisamente declarada e pode ser executada por um computador [^2]. Um algoritmo deve exibir três propriedades essenciais: *definiteness*, *effective computability* e *finiteness* [^2]. *Definiteness* refere-se à noção de que cada etapa é precisamente declarada; não há espaço para ambiguidade sobre o que deve ser feito [^2]. *Effective computability* refere-se ao fato de que cada etapa pode ser executada por um computador [^2]. *Finiteness* significa que o algoritmo deve ter garantia de terminar [^2].

Dado um problema, é possível encontrar vários algoritmos para resolvê-lo [^2]. Alguns requerem menos etapas de computação do que outros; alguns permitem graus mais altos de execução paralela do que outros; alguns têm melhor estabilidade numérica do que outros; e alguns consomem menos largura de banda de memória do que outros [^2]. Infelizmente, muitas vezes não existe um único algoritmo que seja melhor do que os outros em todos os quatro aspectos [^2]. Dado um problema e uma estratégia de decomposição, um programador paralelo geralmente precisa selecionar um algoritmo que obtenha o melhor compromisso para um determinado sistema de hardware [^2].

**Destacando a importância da escolha de algoritmos e decomposição de problemas:**

> Com uma boa decomposição do problema, o programador pode selecionar e implementar algoritmos que alcancem um compromisso apropriado entre paralelismo, eficiência computacional e consumo de largura de banda de memória [^1].

### Conclusão

A computação paralela visa aumentar a velocidade para lidar com problemas maiores e mais complexos, permitindo análises mais rápidas e decisões mais ágeis [^1]. A escolha do algoritmo e a decomposição do problema são etapas cruciais para alcançar os objetivos da computação paralela [^1, 2].

### Referências
[^1]: Parallel Programming and Computational Thinking, p. 281
[^2]: Parallel Programming and Computational Thinking, p. 282

<!-- END -->