## Limitações dos Sistemas CUDA Tradicionais no Lançamento de Kernels

### Introdução

Este capítulo aborda as limitações inerentes aos sistemas CUDA tradicionais, particularmente no que diz respeito ao lançamento de kernels a partir do código host e à determinação do tamanho do grid de threads. A compreensão dessas limitações é crucial para apreciar a evolução e as novas capacidades introduzidas em arquiteturas CUDA mais recentes. A ênfase recairá sobre a dificuldade de implementar espaçamento variável do grid em kernels Single Program, Multiple Data (SPMD) e a prevalência de sistemas com grid fixo [^1].

### Conceitos Fundamentais

Nos sistemas CUDA tradicionais, o lançamento de kernels é orquestrado inteiramente pelo código executado na CPU, também conhecido como *host*. Antes de um kernel ser executado na GPU, o programador deve definir o tamanho do grid (número de blocos) e o tamanho dos blocos (número de threads por bloco). Essa abordagem, embora direta, apresenta uma limitação significativa: o tamanho do grid é fixo e determinado no momento do lançamento do kernel.

A afirmação principal [^1] é que *sistemas CUDA tradicionais lançavam todos os kernels a partir do código host, com um volume de trabalho de grid de threads predeterminado, dificultando o uso de espaçamento de grid variado em kernels Single Program, Multiple Data (SPMD) e favorecendo sistemas de grid fixo*. Vamos desmembrar essa afirmação:

1.  **Lançamento de Kernels a partir do Host:** Em CUDA tradicional, o host (CPU) é responsável por copiar dados para a GPU, configurar e lançar os kernels, e sincronizar a execução.

![Comparison of kernel launch patterns: (a) without dynamic parallelism and (b) with dynamic parallelism.](./../images/image5.jpg)

2.  **Volume de Trabalho de Grid de Threads Predeterminado:** O número total de threads que executarão o kernel é definido antes do lançamento e não pode ser alterado dinamicamente durante a execução do kernel. Se o problema a ser resolvido tiver um tamanho que não se ajusta perfeitamente ao tamanho do grid, pode haver necessidade de threads inativas ou de tratamento especial para os limites.
3.  **Dificultando o Uso de Espaçamento de Grid Variado em Kernels SPMD:** Kernels SPMD (Single Program, Multiple Data) são paradigmas de programação paralela onde o mesmo código é executado em múltiplos dados simultaneamente. Em CUDA, cada thread executa essencialmente o mesmo código, mas opera sobre uma porção diferente dos dados. A dificuldade reside em que, se quisermos que diferentes partes dos dados recebam um tratamento diferente (e.g., computação adaptativa baseada em propriedades locais), a necessidade de um grid fixo impede que a densidade de threads seja adaptada às necessidades computacionais locais.
4.  **Favorecendo Sistemas de Grid Fixo:** Devido às limitações mencionadas, os sistemas CUDA tradicionais tendem a ser projetados com um tamanho de grid fixo, que é adequado para um determinado tamanho de problema. Isso pode levar a ineficiências se o tamanho do problema variar significativamente, pois o grid fixo pode estar subutilizado ou exigir manipulação complexa de limites.

A principal desvantagem de um sistema de grid fixo é sua falta de flexibilidade. Em muitas aplicações, o volume de computação necessário pode variar significativamente de uma região para outra. Por exemplo, em simulações físicas, algumas áreas podem exigir cálculos mais precisos do que outras. Em processamento de imagens, algumas regiões podem conter mais detalhes e, portanto, exigir mais poder de processamento. Em algoritmos de busca, algumas partes do espaço de busca podem ser mais propensas a conter a solução do que outras.

![Illustration comparing fixed versus dynamic grids for turbulence simulation, demonstrating adaptive mesh refinement for performance optimization.](./../images/image2.jpg)

Em todas essas situações, seria ideal poder ajustar dinamicamente o número de threads atribuídos a cada região, alocando mais threads para as regiões que exigem mais computação e menos threads para as regiões que exigem menos computação. No entanto, os sistemas CUDA tradicionais não oferecem esse nível de flexibilidade.

### Conclusão

A arquitetura CUDA tradicional, ao impor um tamanho de grid fixo e um lançamento de kernel orquestrado pelo host, limita a capacidade de adaptar dinamicamente a densidade de threads às necessidades computacionais locais. Isso é particularmente problemático para kernels SPMD, onde diferentes partes dos dados podem exigir diferentes quantidades de computação. A evolução da arquitetura CUDA busca superar essas limitações, permitindo um espaçamento de grid mais flexível e adaptável, o que resulta em maior eficiência e desempenho em uma ampla gama de aplicações.

### Referências
[^1]: Traditional CUDA systems launched all kernels from the host code, with a predetermined thread grid work amount, hindering the use of varied grid spacing in Single Program, Multiple Data (SPMD) kernels and favoring fixed-grid systems.
<!-- END -->