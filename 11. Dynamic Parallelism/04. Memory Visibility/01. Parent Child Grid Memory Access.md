## Coerência da Memória Global entre Grades Pai e Filho em CUDA

### Introdução

Este capítulo explora a coerência da memória global entre *grids* pai e filho na programação CUDA, um aspecto crucial para garantir a correção e o desempenho de aplicações complexas que utilizam *grid-launching* em paralelo. Especificamente, analisaremos como a memória global é acessada e sincronizada entre o *grid* pai (que lança o *grid* filho) e o *grid* filho, focando nas garantias de consistência fraca fornecidas pela arquitetura CUDA [^1]. A compreensão dessas garantias é fundamental para evitar *race conditions* e assegurar que os dados compartilhados entre os *grids* sejam consistentes.

### Conceitos Fundamentais

Em CUDA, *grids* pai e filho possuem acesso coerente à memória global, o que significa que as operações de leitura e escrita na memória global são visíveis para todos os *threads* em todos os *grids*. No entanto, essa coerência vem com garantias de consistência fraca [^1]. Isso significa que a ordem em que as operações de memória são executadas não é estritamente imposta, a menos que mecanismos de sincronização explícitos sejam utilizados.

A consistência fraca implica que as atualizações feitas por um *thread* em um *grid* podem não ser imediatamente visíveis para outros *threads* em outro *grid*. Essa latência na visibilidade das atualizações pode levar a comportamentos inesperados se não for gerenciada corretamente.

![Parent-child kernel launch nesting demonstrating CUDA dynamic parallelism execution flow.](./../images/image3.jpg)

A garantia de que a visão da memória de um *grid* filho é totalmente consistente com o *thread* pai ocorre em dois pontos específicos [^1]:

1.  **Criação do *grid* filho:** No momento em que o *grid* filho é lançado, sua visão da memória global é consistente com o estado da memória conforme visto pelo *thread* pai que o lançou. Isso implica que todas as escritas na memória global feitas pelo *thread* pai antes do lançamento do *grid* filho são visíveis para todos os *threads* no *grid* filho.
2.  **Conclusão do *grid* filho:** Quando o *grid* filho completa sua execução, sinalizado por uma chamada de API de sincronização no *grid* pai, todas as escritas feitas pelos *threads* no *grid* filho são garantidas serem visíveis para o *thread* pai.

É importante ressaltar que a sincronização explícita no *grid* pai, após o lançamento do *grid* filho, é *essencial* para garantir a visibilidade das alterações feitas pelo *grid* filho [^1]. APIs de sincronização como `cudaDeviceSynchronize()` ou eventos CUDA são comumente usadas para esse propósito.

**Exemplo:**

Considere um cenário onde um *grid* pai lança um *grid* filho para realizar um cálculo e armazenar o resultado na memória global. Se o *grid* pai tentar ler esse resultado imediatamente após o lançamento do *grid* filho, sem uma sincronização adequada, ele pode ler um valor desatualizado ou inconsistente.

Para ilustrar, considere o seguinte pseudo-código:

**Código no *grid* pai:**

```c++
// Aloca memória global
float *d_result;
cudaMalloc(&d_result, sizeof(float));

// Define o valor inicial
cudaMemcpy(d_result, &initialValue, sizeof(float), cudaMemcpyHostToDevice);

// Lança o grid filho
myKernel<<<gridSize, blockSize>>>(d_result);

// SEM SINCRONIZAÇÃO - Leitura potencialmente inconsistente
float result;
cudaMemcpy(&result, d_result, sizeof(float), cudaMemcpyDeviceToHost);

printf("Resultado: %f\n", result);
```

**Kernel executado no *grid* filho:**

```c++
__global__ void myKernel(float *d_result) {
  // Calcula o resultado
  float calculatedResult = ...;
  // Escreve o resultado na memória global
  *d_result = calculatedResult;
}
```

Neste exemplo, o *grid* pai pode imprimir um valor incorreto para `result` se a escrita em `*d_result` pelo *grid* filho não estiver completa antes da leitura no *grid* pai.

Para corrigir isso, a sincronização deve ser adicionada no *grid* pai:

**Código corrigido no *grid* pai:**

```c++
// Aloca memória global
float *d_result;
cudaMalloc(&d_result, sizeof(float));

// Define o valor inicial
cudaMemcpy(d_result, &initialValue, sizeof(float), cudaMemcpyHostToDevice);

// Lança o grid filho
myKernel<<<gridSize, blockSize>>>(d_result);

// SINCRONIZAÇÃO - Garante a consistência da memória
cudaDeviceSynchronize();

// Leitura consistente
float result;
cudaMemcpy(&result, d_result, sizeof(float), cudaMemcpyDeviceToHost);

printf("Resultado: %f\n", result);
```

A chamada a `cudaDeviceSynchronize()` garante que o *grid* pai espere até que todos os *grids* lançados (incluindo o *grid* filho) tenham completado a execução antes de prosseguir com a leitura dos resultados.

![Memory allocation and deallocation behavior of `cudaMalloc()` and `cudaFree()` from host and device.](./../images/image1.jpg)

### Conclusão

A coerência da memória global entre *grids* pai e filho é uma característica fundamental da arquitetura CUDA, mas requer uma compreensão cuidadosa das garantias de consistência fraca. A sincronização explícita é essencial para garantir que as atualizações feitas por um *grid* sejam visíveis para outros, evitando condições de corrida e inconsistências nos dados. O uso correto de APIs de sincronização como `cudaDeviceSynchronize()` ou eventos CUDA é crucial para o desenvolvimento de aplicações CUDA robustas e corretas que utilizam *grid-launching*. O conhecimento aprofundado desses mecanismos permite aos desenvolvedores otimizar o desempenho enquanto mantêm a integridade dos dados.

### Referências
[^1]: Descrição do tópico fornecida.
<!-- END -->