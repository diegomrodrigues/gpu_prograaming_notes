## Convolução Paralela 1D com Máscaras de Tamanho Ímpar e Simetria

### Introdução

Este capítulo aprofunda o estudo da convolução paralela 1D utilizando CUDA e programação de GPU, focando especificamente no cenário onde as máscaras de convolução possuem tamanho ímpar e exibem simetria. A convolução é uma operação fundamental em processamento de sinais e imagens, amplamente utilizada para filtragem, suavização e detecção de bordas. Ao explorar a otimização dessa operação em arquiteturas paralelas como as GPUs, podemos obter ganhos significativos em desempenho, especialmente para conjuntos de dados de grande escala.

### Conceitos Fundamentais

Em continuidade aos conceitos introduzidos anteriormente sobre convolução, vamos detalhar a implementação para o caso específico de máscaras com tamanho ímpar e simetria [^4]. A simetria da máscara implica que os coeficientes são espelhados em relação ao centro, simplificando algumas operações e permitindo otimizações no código.

Para uma máscara de tamanho ímpar, `Mask_Width`, o cálculo de cada elemento de saída `P[i]` utiliza elementos de entrada de `N[i-n]` a `N[i+n]`, onde `n = Mask_Width / 2` [^4]. Note que, como `Mask_Width` é ímpar, a divisão por 2 resulta em um número inteiro, representando o número de elementos de cada lado do elemento central da máscara.

A seguir, ilustramos o cálculo de `P[i]` utilizando um loop simples:

```c++
float sum = 0.0f;
for (int j = -n; j <= n; ++j) {
  sum += Mask[j + n] * N[i + j];
}
P[i] = sum;
```

Neste trecho de código:

*   `sum` acumula o resultado da convolução para o elemento `P[i]`.
*   O loop itera sobre os elementos da máscara, de `-n` a `n`.
*   `Mask[j + n]` acessa o coeficiente apropriado da máscara. A adição de `n` garante que o índice esteja dentro dos limites da máscara (0 a `Mask_Width - 1`).
*   `N[i + j]` acessa o elemento correspondente do sinal de entrada.

**Considerações sobre limites:** É crucial lidar corretamente com os limites do sinal de entrada `N`. Quando `i + j` está fora dos limites de `N`, uma estratégia comum é preencher com zeros (zero-padding) ou replicar os valores das bordas. A escolha da estratégia depende da aplicação e do efeito desejado na borda do sinal de saída.

![1D convolution with boundary conditions, showing input array N, mask M, and output array P, where missing elements are padded with zeros.](./../images/image6.jpg)

**Exemplo:**

Considere um sinal de entrada `N = [1, 2, 3, 4, 5]` e uma máscara simétrica de tamanho 3, `Mask = [0.1, 0.8, 0.1]`. Então `n = 3 / 2 = 1`.

![1D convolution example showing calculation of P[3] based on input array N and mask M.](./../images/image11.jpg)

Para calcular `P[2]`, iteramos de `j = -1` a `j = 1`:

*   `j = -1`:  `Mask[-1 + 1] * N[2 - 1] = Mask[0] * N[1] = 0.1 * 2 = 0.2`
*   `j = 0`:   `Mask[0 + 1] * N[2 + 0] = Mask[1] * N[2] = 0.8 * 3 = 2.4`
*   `j = 1`:   `Mask[1 + 1] * N[2 + 1] = Mask[2] * N[3] = 0.1 * 4 = 0.4`

Portanto, `P[2] = 0.2 + 2.4 + 0.4 = 3.0`.

**Paralelização:**

Embora o loop simples apresentado seja funcional, ele não explora o potencial de paralelização oferecido pelas GPUs. Cada elemento `P[i]` pode ser calculado independentemente, tornando a convolução naturalmente paralelizável. Em CUDA, cada thread pode ser responsável por calcular um ou mais elementos de `P`.

![CUDA kernel for 1D convolution, demonstrating parallel computation of output elements.](./../images/image3.jpg)

Um kernel CUDA típico para essa operação pode ser estruturado da seguinte forma:

```c++
__global__ void convolution1DKernel(float* N, float* Mask, float* P, int N_width, int Mask_Width) {
  int i = blockIdx.x * blockDim.x + threadIdx.x; // Calcula o índice global

  if (i < N_width) {
    int n = Mask_Width / 2;
    float sum = 0.0f;

    for (int j = -n; j <= n; ++j) {
      int index = i + j;

      // Lidar com os limites (exemplo: zero-padding)
      if (index < 0 || index >= N_width) {
        sum += 0.0f; // Zero-padding
      } else {
        sum += Mask[j + n] * N[index];
      }
    }
    P[i] = sum;
  }
}
```

Neste kernel:

*   `blockIdx.x`, `blockDim.x` e `threadIdx.x` são variáveis intrínsecas do CUDA que identificam o bloco e a thread em execução.
*   `i` calcula o índice global do elemento `P[i]` que a thread deve calcular.
*   O condicional `if (i < N_width)` garante que a thread não acesse memória fora dos limites de `P`.
*   A seção para lidar com os limites implementa zero-padding.

![CUDA memory model: Grid of blocks with shared memory, registers, and threads interacting with global and constant memory.](./../images/image10.jpg)

### Conclusão

A convolução paralela 1D com máscaras de tamanho ímpar e simetria oferece um excelente ponto de partida para explorar a programação de GPU utilizando CUDA [^4]. A simplicidade do algoritmo permite uma fácil implementação e compreensão dos conceitos fundamentais de paralelização. O kernel CUDA apresentado pode ser otimizado ainda mais através de técnicas como o uso de memória compartilhada para reduzir o acesso à memória global e o *loop unrolling* para melhorar o desempenho do loop interno. A correta manipulação dos limites é crucial para a exatidão do resultado e a estabilidade do código.

### Referências

[^4]: For odd-sized masks and symmetrical convolution, the calculation of each output element P[i] uses input elements from N[i-n] to N[i+n], where n = Mask_Width / 2. A simple loop can be used to perform this calculation.
<!-- END -->