## 5.2 CUDA Device Memory Types

### Introdução
Este capítulo explora os diferentes tipos de memória suportados pela CUDA, com foco em como cada tipo de memória contribui para otimizar o CGMA (compute to global memory access) ratio e, consequentemente, a velocidade de execução dos kernels [^95]. CUDA oferece vários tipos de memória para atingir um alto CGMA e velocidade de execução, incluindo memória global (acessível pelo host por meio de chamadas de API), memória constante e memórias on-chip, como registradores e memória compartilhada [^95]. Compreender as características e o uso adequado de cada tipo de memória é fundamental para otimizar o desempenho de aplicações CUDA.

### Conceitos Fundamentais

#### Tipos de Memória CUDA
CUDA suporta vários tipos de memória que podem ser usados por programadores para atingir um alto CGMA ratio e, portanto, uma alta velocidade de execução em seus kernels [^97]. Esses tipos de memória incluem:

*   **Memória Global:** A memória global é o tipo de memória mais amplo e acessível no dispositivo CUDA [^95]. É acessível tanto pelo host (CPU) quanto pelo dispositivo (GPU) através de chamadas de API [^95, 97]. A memória global é implementada tipicamente com DRAM (dynamic random access memory), o que resulta em longas latências de acesso (centenas de ciclos de clock) e largura de banda de acesso finita [^95]. Embora muitos threads disponíveis para execução possam teoricamente tolerar longas latências de acesso à memória, pode-se facilmente entrar em uma situação onde o congestionamento do tráfego nos caminhos de acesso à memória global impede que todos, exceto alguns threads, progridam, tornando alguns dos multiprocessadores de streaming (SMs) ociosos [^95].

*   **Memória Constante:** A memória constante é outro tipo de memória acessível tanto pelo host quanto pelo dispositivo [^97]. Ela é otimizada para acesso de leitura de alta largura de banda e baixa latência pelo dispositivo quando todos os threads acessam simultaneamente o mesmo local [^97]. As variáveis constantes são armazenadas na memória global, mas são armazenadas em cache para acesso eficiente [^104]. O escopo de uma variável constante é todos os grids, o que significa que todos os threads em todos os grids veem a mesma versão de uma variável constante [^104]. O tempo de vida de uma variável constante é a execução inteira da aplicação [^104]. Atualmente, o tamanho total de variáveis constantes em uma aplicação é limitado a 65.536 bytes [^104].

*   **Registradores:** Os registradores são memórias on-chip que são alocadas a threads individuais [^97]. Cada thread só pode acessar seus próprios registradores [^97]. Uma função kernel tipicamente usa registradores para armazenar variáveis acessadas frequentemente que precisam ser acessadas de forma extremamente rápida [^97]. As variáveis automáticas escalares declaradas em funções kernel e de dispositivo são colocadas em registradores [^102]. O escopo dessas variáveis automáticas está dentro de threads individuais [^102].

*   **Memória Compartilhada:** A memória compartilhada é outra forma de memória on-chip que é alocada a blocos de threads [^97]. Todos os threads em um bloco podem acessar variáveis nos locais de memória compartilhada alocados ao bloco [^97]. A memória compartilhada é um meio eficiente para os threads cooperarem compartilhando seus dados de entrada e os resultados intermediários de seu trabalho [^97]. A memória compartilhada é projetada como parte do espaço de memória que reside no chip do processador (veja a Seção 4.2) [^101]. Quando o processador acessa dados que residem na memória compartilhada, ele precisa executar uma operação de carregamento de memória, assim como o acesso a dados na memória global [^101]. No entanto, como a memória compartilhada reside no chip, ela pode ser acessada com latência muito menor e largura de banda muito maior do que a memória global [^101].

#### Compute to Global Memory Access (CGMA) Ratio

O CGMA ratio é definido como o número de cálculos de ponto flutuante realizados para cada acesso à memória global dentro de uma região de um programa CUDA [^96]. Um alto CGMA ratio implica que o kernel está realizando mais cálculos por acesso à memória global, o que pode levar a um melhor desempenho [^96].

#### Implicações do CGMA
O CGMA tem implicações importantes no desempenho de um kernel CUDA [^96]. Em um dispositivo high-end hoje, a largura de banda da memória global é de cerca de 200 GB/s [^96]. Com 4 bytes em cada valor de ponto flutuante de precisão única, pode-se esperar carregar não mais que 50 (200/4) giga operandos de precisão única por segundo [^96]. Com um CGMA ratio de 1.0, o kernel de multiplicação de matrizes executará não mais que 50 giga operações de ponto flutuante por segundo (GFLOPS) [^96]. Embora 50 GFLOPS seja um número respeitável, é apenas uma pequena fração do desempenho de precisão única de pico de 1.500 GFLOPS ou superior para esses dispositivos high-end [^96]. Precisamos aumentar o CGMA ratio para atingir um nível mais alto de desempenho para o kernel [^96]. Para que o código de multiplicação de matrizes atinja a classificação de 1.500 GFLOPS de pico do processador, precisamos de um valor CGMA de 30 [^96]. O CGMA ratio desejado dobrou aproximadamente nas últimas três gerações de dispositivos [^96].

### Conclusão
CUDA oferece uma variedade de tipos de memória para permitir que os programadores otimizem o desempenho de seus kernels [^95, 97]. A escolha do tipo de memória apropriado depende dos requisitos específicos do kernel, incluindo padrões de acesso à memória, necessidades de compartilhamento de dados e restrições de capacidade [^97, 102]. Ao entender as características e limitações de cada tipo de memória, os programadores podem escrever kernels CUDA mais eficientes que alcançam um alto CGMA ratio e maximizam o desempenho do dispositivo CUDA [^96].

### Referências
[^95]: Capítulo 5, página 95.
[^96]: Capítulo 5, página 96.
[^97]: Capítulo 5, página 97.
[^101]: Capítulo 5, página 101.
[^102]: Capítulo 5, página 102.
[^104]: Capítulo 5, página 104.
<!-- END -->