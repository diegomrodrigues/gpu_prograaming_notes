## Shared Memory vs. Registers: Functionality and Access Cost

### Introdução
No contexto de arquiteturas CUDA, a eficiência no acesso à memória é um fator crítico para o desempenho de kernels. Vimos anteriormente [^95] que a performance dos kernels CUDA é limitada pelas características da memória global, que possui alta latência e largura de banda finita devido à sua implementação em DRAM. Para mitigar essas limitações, CUDA oferece diferentes tipos de memória, cada um com suas próprias características de acesso e funcionalidades [^97]. Este capítulo aprofunda a comparação entre **shared memory** e **registers**, dois tipos de memória *on-chip* que desempenham um papel fundamental na otimização do desempenho [^97].

### Conceitos Fundamentais
**Registers** e **shared memory** são tipos de memória *on-chip* que permitem acesso de alta velocidade e em paralelo [^97]. No entanto, eles diferem significativamente em termos de funcionalidade e custo de acesso [^101].

*   **Registers:** São alocados para threads individuais, e cada thread só pode acessar seus próprios registers [^97]. Eles são usados para armazenar variáveis frequentemente acessadas por um thread, como os índices de linha e coluna (`Row`, `Col`) e o valor parcial do produto (`Pvalue`) no exemplo da multiplicação de matrizes [^97, 103]. A declaração de variáveis automáticas (não arrays) em funções kernel ou device resulta na alocação destas em registers [^102]. O acesso a registers é extremamente rápido e paralelo, mas a capacidade é limitada [^103].

*   **Shared Memory:** É alocada para blocos de threads, e todos os threads dentro de um bloco podem acessar variáveis localizadas na shared memory [^98]. Shared memory permite que threads cooperem, compartilhando dados de entrada e resultados intermediários [^98]. A declaração de uma variável com o qualificador `__shared__` em CUDA aloca essa variável na shared memory [^103].

**Diferenças Cruciais:**

1.  **Escopo:** Registers são privados para cada thread, enquanto shared memory é compartilhada entre todos os threads em um bloco [^101].
2.  **Acesso:** O acesso a registers é mais rápido do que o acesso a shared memory [^101]. Isso ocorre porque o acesso a shared memory requer uma operação de load, similar ao acesso à memória global, embora com latência menor [^101].
3.  **Funcionalidade:** Registers são usados para armazenar dados privados de um thread, enquanto shared memory é usada para comunicação e compartilhamento de dados entre threads em um bloco [^97].
4. **Implementação:** A memória global é implementada com tecnologia DRAM, que resulta em longas latências de acesso e largura de banda relativamente baixa. Os registers, por outro lado, correspondem ao "register file" do modelo de von Neumann, localizados no chip do processador, o que implica em latência de acesso muito curta e largura de banda drasticamente maior [^98].

**Vantagens da Shared Memory:**

Apesar da latência ligeiramente maior em comparação com registers, a shared memory oferece vantagens significativas:

*   **Compartilhamento de Dados:** Permite que threads em um bloco compartilhem dados de forma eficiente, reduzindo a necessidade de acessos à memória global [^98]. Isso é crucial para algoritmos que exigem comunicação entre threads, como a multiplicação de matrizes com tiling [^109].
*   **Redução do Tráfego de Memória Global:** Ao armazenar dados frequentemente acessados na shared memory, o número de acessos à memória global é reduzido, melhorando o desempenho [^98].
* **Aumento do CGMA Ratio:** Ao utilizar registers e shared memory para armazenar dados acessados frequentemente, o número de acessos à memória global é reduzido, o que se reflete em um aumento no *compute to global memory access (CGMA)* ratio [^98].

**Exemplo: Multiplicação de Matrizes com Tiling**

A técnica de **tiling** ilustra o uso eficiente da shared memory para otimizar o acesso à memória [^105]. Em vez de cada thread acessar diretamente a memória global para buscar os elementos da matriz, os threads colaboram para carregar um "tile" (subconjunto) da matriz na shared memory [^109]. Cada thread carrega um elemento do tile para a shared memory [^110]. Após o carregamento, os threads podem acessar os elementos do tile na shared memory para realizar os cálculos, reduzindo drasticamente o número de acessos à memória global [^111].

No kernel de multiplicação de matrizes com tiling [^112], as variáveis `Mds` e `Nds` são declaradas como shared memory [^112]. Os threads em um bloco carregam colaborativamente tiles das matrizes `d_M` e `d_N` para `Mds` e `Nds`, respectivamente [^112]. A barreira `__syncthreads()` garante que todos os threads tenham terminado de carregar os tiles antes de iniciar os cálculos [^114].

### Conclusão
A escolha entre registers e shared memory depende das necessidades específicas do kernel. Registers são ideais para armazenar dados privados e frequentemente acessados por um único thread, enquanto shared memory é essencial para permitir a comunicação e o compartilhamento de dados entre threads em um bloco, otimizando o acesso à memória global e, consequentemente, o desempenho do kernel [^101]. A utilização eficiente da shared memory, como demonstrado na técnica de tiling, é crucial para alcançar alto desempenho em aplicações CUDA [^111]. A combinação estratégica de registers e shared memory permite maximizar a localidade dos dados e reduzir a dependência da memória global, resultando em kernels mais rápidos e eficientes.

### Referências
[^95]: Capítulo 5, página 95
[^97]: Capítulo 5, página 97
[^98]: Capítulo 5, página 98
[^101]: Capítulo 5, página 101
[^102]: Capítulo 5, página 102
[^103]: Capítulo 5, página 103
[^105]: Capítulo 5, página 105
[^109]: Capítulo 5, página 109
[^110]: Capítulo 5, página 110
[^111]: Capítulo 5, página 111
[^112]: Capítulo 5, página 112
[^114]: Capítulo 5, página 114
<!-- END -->