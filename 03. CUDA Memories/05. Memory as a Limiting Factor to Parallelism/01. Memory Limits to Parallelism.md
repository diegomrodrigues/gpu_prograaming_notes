## Memória como um Fator Limitante para o Paralelismo em CUDA

### Introdução
Como vimos anteriormente, a eficiência no acesso à memória é crucial para o desempenho de kernels CUDA [^96]. Registradores e memória compartilhada são recursos valiosos para minimizar o tráfego de memória global [^115]. No entanto, é imperativo considerar as limitações de capacidade desses recursos, pois eles são essenciais para a execução das threads [^115]. Este capítulo explora como o uso inadequado ou excessivo desses recursos pode se tornar um gargalo, limitando o grau de paralelismo que pode ser alcançado em um dispositivo CUDA.

### Conceitos Fundamentais

**A Importância dos Registradores e da Memória Compartilhada:**

Registradores e memória compartilhada são memórias *on-chip* que oferecem acesso de alta velocidade e baixa latência, contrastando com a memória global, que reside *off-chip* e possui maior latência e menor largura de banda [^97, 98]. Ao armazenar dados frequentemente acessados nesses recursos, o número de acessos à memória global pode ser significativamente reduzido, melhorando o desempenho geral do kernel [^97, 100].

**Capacidade Limitada:**

Apesar de suas vantagens, registradores e memória compartilhada possuem capacidade limitada. O número de registradores disponíveis para cada thread e a quantidade de memória compartilhada disponível para cada bloco de threads são finitos e dependentes da arquitetura do dispositivo CUDA [^115, 116].

**Oversubscription de Registradores:**

Se um kernel utilizar um número excessivo de registradores por thread, o número de threads que podem residir simultaneamente em um Streaming Multiprocessor (SM) será reduzido [^115]. Isso impacta diretamente o paralelismo, pois menos threads estarão disponíveis para executar, diminuindo a capacidade do processador de ocultar a latência de operações de memória e outras operações [^116]. Por exemplo, se um SM pode acomodar até 1536 threads e possui 16384 registradores, cada thread pode usar apenas 10 registradores. Se cada thread usar 11 registradores, o número de threads capazes de executar concorrentemente no SM será reduzido [^115]. Essa redução é feita na granularidade do bloco [^115].

**Uso da Memória Compartilhada:**

A memória compartilhada é alocada para blocos de threads e permite que as threads dentro de um bloco cooperem compartilhando dados [^98]. No entanto, cada SM possui uma quantidade limitada de memória compartilhada [^116]. Se cada bloco utilizar uma grande quantidade de memória compartilhada, o número de blocos que podem residir simultaneamente em um SM será limitado [^116]. Como cada SM pode acomodar até oito blocos, cada bloco não deve usar mais que 2K bytes de memória compartilhada [^116].

**Exemplo de Multiplicação de Matrizes:**

Na multiplicação de matrizes com *tiling*, a memória compartilhada pode se tornar um fator limitante [^116]. Para um tamanho de *tile* de 16x16, cada bloco precisa de 1KB de armazenamento para `Mds` e 1KB para `Nds`, totalizando 2KB de memória compartilhada por bloco [^116]. Uma memória compartilhada de 16KB permite que oito blocos residam simultaneamente em um SM [^116].

**Ajuste Dinâmico da Memória Compartilhada:**

O tamanho da memória compartilhada em cada SM pode variar de dispositivo para dispositivo [^117]. É desejável que um kernel seja capaz de usar uma quantidade diferente de memória compartilhada de acordo com a quantidade disponível no hardware [^117]. Isso pode ser feito chamando a função `cudaGetDeviceProperties()` [^116, 117].

**Declarando Memória Compartilhada:**

Para permitir um ajuste dinâmico, pode-se adicionar uma palavra-chave `extern` C em frente à declaração da memória compartilhada e omitir o tamanho do array na declaração [^117]. Por exemplo:
```c++
extern __shared__ float Mds[];
extern __shared__ float Nds[];
```
Observe que os arrays agora são unidimensionais [^117]. No tempo de execução, quando lançamos o kernel, podemos determinar dinamicamente a quantidade de memória compartilhada a ser usada de acordo com a consulta do dispositivo e fornecer isso como um terceiro parâmetro de configuração para o kernel [^117]. Por exemplo, a instrução de lançamento do kernel na Figura 4.18 poderia ser substituída pelas seguintes declarações [^118]:
```c++
size_t size = calculate_appropriate_SM_usage(dev_prop.sharedMemPerBlock,...);
matrixMulKernel<<<dimGrid, dimBlock, size>>>(Md, Nd, Pd, Width);
```

**Gerenciamento de Recursos e Paralelismo:**

O gerenciamento eficiente de registradores e memória compartilhada é fundamental para maximizar o paralelismo em CUDA. Alocar recursos em excesso para cada thread ou bloco pode reduzir o número total de threads e blocos que podem ser executados simultaneamente, levando a uma subutilização do hardware e a um desempenho inferior [^115].

### Conclusão

Em resumo, embora registradores e memória compartilhada sejam ferramentas poderosas para otimizar o desempenho de kernels CUDA, é essencial estar ciente de suas limitações de capacidade [^118]. O uso cuidadoso e equilibrado desses recursos é crucial para atingir o máximo paralelismo e, consequentemente, o melhor desempenho possível em aplicações CUDA [^115]. A capacidade de raciocinar sobre as limitações de hardware ao desenvolver um aplicativo é um aspecto chave do pensamento computacional [^118].

### Referências
[^96]: Página 96, Capítulo 5, CUDA Memories
[^97]: Página 97, Capítulo 5, CUDA Memories
[^98]: Página 98, Capítulo 5, CUDA Memories
[^100]: Página 100, Capítulo 5, CUDA Memories
[^115]: Página 115, Capítulo 5, CUDA Memories
[^116]: Página 116, Capítulo 5, CUDA Memories
[^117]: Página 117, Capítulo 5, CUDA Memories
[^118]: Página 118, Capítulo 5, CUDA Memories
$\blacksquare$
<!-- END -->